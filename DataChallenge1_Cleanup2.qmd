---
title: "Data Challenge 1"
author: "Saskia Gianola / Sarah Wirth"
date: "October/November 2024"
format: 
  html:
    embed-resources: true
    fig_caption: true
    fig-align: center
    highlight: tango
    number-sections: false
    theme: journal
    toc: true
    toc_depth: 2
    toc_float: true
execute:                      # Set global options for execution of code blocks
  echo: false
  warning: false
  message: false
---
# Introduction
This file includes the assignments, code and interpretation of Data Challenge 1. The code was elaborated as collaboration between Sarah Wirth and Saskia Gianola. For this work no language models like ChatGPT have been used.

## Packages
```{r}
library(dplyr)
library(ggplot2)
library(lubridate)
library(sf)
library(cluster)
library(dbscan)
library(fpc)
library(concaveman)
library(adehabitatHR)
library(spatstat)
library(spdep)
library(ks)

```

# First part: Spatial Clustering
## Task 1
Download and import the road accident data from Open Data Zurich (ODZ) using an appropriate file format. If needed, transform to the Swiss projected CH1903+/LV95 coordinate system (EPSG = 2056).

```{r, echo=TRUE, , results='hide'}
accidents <- st_read("Session2/roadtrafficaccidentlocations.gpkg")
boundary <-st_read("Session2/Zurich_city_boundary_2024.gpkg")
districts <-st_read("Session2/Zurich_city_districts_2024.gpkg")
```
As all three layers are already in the Swiss projected CH1903+/LV95, there is no need for transformation. 

## Task 2
Report the following numbers in table(s):
  
```{r}
accidents_no_geom <- st_drop_geometry(accidents) # drop geometry to make code more efficient

acc_sever <- accidents_no_geom |> 
   count(AccidentSeverityCategory_en)

acc_type <- accidents_no_geom |> 
  count(AccidentType_en)

acc_ped <- accidents_no_geom |> 
  count(AccidentInvolvingPedestrian)

acc_bike <- accidents_no_geom |> 
  count(AccidentInvolvingBicycle)

acc_moto <- accidents_no_geom |> 
  count(AccidentInvolvingMotorcycle)

acc_ped_moto <- accidents_no_geom |> 
  count(AccidentInvolvingPedestrian, AccidentInvolvingMotorcycle)

acc_ped_bike <- accidents_no_geom |> 
  count(AccidentInvolvingPedestrian, AccidentInvolvingBicycle)

acc_moto_bike <- accidents_no_geom |> 
  count(AccidentInvolvingMotorcycle, AccidentInvolvingBicycle)

acc_ped_bike_moto <- accidents_no_geom |> 
  count(AccidentInvolvingPedestrian, AccidentInvolvingBicycle, AccidentInvolvingMotorcycle)
  
```
* a. Number of accidents by accident severity category
  
```{r}
acc_sever
```
  
* b. Number of accidents by accident type
  
```{r}
acc_type
```

  
* c. Number of accidents involving pedestrians, bicycles, and motorcycles, respectively. And combinations thereof (pedestrian AND bicycle, pedestrian AND motorcycle etc.). Are there any accidents involving all three modes (pedestrian, bicycle, motorcycle)?
  
```{r}
acc_ped
acc_bike
acc_moto
acc_ped_bike
acc_ped_moto
acc_moto_bike
acc_ped_bike_moto
```

## Task 3
Generate a plot showing the temporal evolution of the number of accidents from 2011 to 2023. Label each year with the corresponding number of accidents. Choose a plot type that is suitable for this type of temporal data. Bonus: Show also the data for the bicycle accidents (cf. Task 4) in the same plot.

```{r, echo=FALSE}
numyearbi <- accidents |> group_by(AccidentYear, AccidentInvolvingBicycle) |>
  summarise(n=n())
numyear <- numyearbi |> group_by(AccidentYear)  |> 
  summarise(n=n())
  

ggplot(numyearbi, aes(x=AccidentYear, y=n,fill=AccidentInvolvingBicycle, label=n)) +
  geom_bar(position="stack", stat="identity")+
  geom_text(size = 3, position = position_stack(vjust = 0.5)) +
  ylab("Total number of accidents") +
  xlab("Year") +
  theme_bw()+
  guides(fill=guide_legend(title="Accident involves bicycles"))

```

## Task 4
Select only those accidents that involved a bicycle. **From now on, and for the remainder of DC1, we will restrict our analysis to the accidents involving bicycles.** With this subset, produce a map showing the bicycle accident data colored by accident severity category. Use a basemap such as OpenStreetMap and/or the boundary data available on OLAT, so the accidents can be visually and spatially referenced.

::: {.panel-tabset .nav-pills}

# All bike accidents
```{r, echo=FALSE}
bike_accidents <- accidents |> 
  filter(AccidentInvolvingBicycle == "true")


#Version normal
ggplot() +
  geom_sf(data = bike_accidents, mapping = aes(color = AccidentSeverityCategory)) +
  geom_sf(data = districts, color = "black", fill = NA) +
  coord_sf(datum = NA)+
  theme(legend.position = "bottom", panel.grid.major = element_line(colour = "transparent")) +
  theme_minimal()+
  scale_color_manual(values = c("red","orange2",  "gold", "blue"),
                               name = "Accident Severity",
                               breaks = c("as1",  "as3","as2", "as4"),
                               labels = c("fatalities", 
                                          "severe injuries",
                                          "light injuries",
                                          "property damage"))
#Version mit alpha
# ggplot() +
#   geom_sf(data = bike_accidents, mapping = aes(color =AccidentSeverityCategory)) +
#   geom_sf(data = districts, color = "black", fill = NA, ) +
#   coord_sf(datum = NA)+
#   theme(legend.position = "bottom", panel.grid.major = element_line(colour = "transparent")) +
#   theme_minimal()+
#   scale_color_manual(values = c(alpha("red",alpha = 1.0), alpha("orange2",alpha = 0.8), alpha("gold",alpha = 0.8), alpha("blue",alpha = 0.8)),
#                                name = "Accident Severity",
#                                breaks = c("as1",  "as3","as2", "as4"),
#                                labels = c("fatalities", 
#                                           "severe injuries",
#                                           "light injuries",
#                                           "property damage"))
# 
# #Version mit small multiples
# ggplot() +
#   geom_sf(data = bike_accidents, mapping = aes(color = AccidentSeverityCategory)) +
#   geom_sf(data = districts, color = "black", fill = NA) +
#   facet_wrap(~AccidentSeverityCategory)+
#   coord_sf(datum = NA)+
#   theme(legend.position = "bottom", panel.grid.major = element_line(colour = "transparent")) +
#   theme_minimal()+
#   theme(strip.text = element_blank())+
#   scale_color_manual(values = c("red","orange2",  "gold", "blue"),
#                                name = "Accident Severity",
#                                breaks = c("as1",  "as3","as2", "as4"),
#                                labels = c("fatalities", 
#                                           "severe injuries",
#                                           "light injuries",
#                                           "property damage"))
```
# bike accidents with fatalities
```{r}
bike_accidents_fatal <- bike_accidents |> 
  filter(AccidentSeverityCategory == "as1")

ggplot() +
  geom_sf(data = bike_accidents_fatal, color = "red") +
  geom_sf(data = districts, color = "black", fill = NA, ) +
  coord_sf(datum = NA)+
  theme_minimal()
```
# bike accidents with severe injuries
```{r}
bike_accidents_severe <- bike_accidents |> 
  filter(AccidentSeverityCategory == "as2")

ggplot() +
  geom_sf(data = bike_accidents_severe, color = "orange2") +
  geom_sf(data = districts, color = "black", fill = NA, ) +
  coord_sf(datum = NA)+
  theme_minimal()
```
# bike accidents with light injuries
```{r}
bike_accidents_light <- bike_accidents |> 
  filter(AccidentSeverityCategory == "as3")

ggplot() +
  geom_sf(data = bike_accidents_light, color = "gold") +
  geom_sf(data = districts, color = "black", fill = NA, ) +
  coord_sf(datum = NA)+
  theme_minimal()
```
# bike accidents with property damage
```{r}
bike_accidents_damage <- bike_accidents |> 
  filter(AccidentSeverityCategory == "as4")

ggplot() +
  geom_sf(data = bike_accidents_damage, color = "blue") +
  geom_sf(data = districts, color = "black", fill = NA, ) +
  coord_sf(datum = NA)+
  theme_minimal()
```
::: 

## Task 5 
Imagine you are given the task of detecting spatial clusters of elevated bicycle accident occurrence (without considering their severity). How would you characterize such "bicycle accident clusters"? Try to define properties that can be used to describe and identify such clusters, and that can be used to choose and parameterize a clustering method suitable for the task. Try to use natural, but precise and concise language in your answer.

KOMMENTAR


## Task 6
From the bicycle accidents, extract the years 2018 to 2021 and compute clusters for each year separately, using a clustering method you deem appropriate for the task, and choose the control parameters appropriately to capture the types of clusters you had in mind in your definition of Task 5. Justify your choice.

```{r, echo=FALSE}
bike_accidents2018 <- st_coordinates(bike_accidents |> 
  filter(AccidentYear == "2018"))
bike_accidents2019 <- st_coordinates(bike_accidents |> 
  filter(AccidentYear == "2019"))
bike_accidents2020 <- st_coordinates(bike_accidents |> 
  filter(AccidentYear == "2020"))
bike_accidents2021 <- st_coordinates(bike_accidents |> 
  filter(AccidentYear == "2021"))
```

::: {.panel-tabset .nav-pills}
## Reachability Plot 2018 data

######Anpassung Werte basierend auf Daten von 2019 -> Saskia was suchen, dass Sinn ergibt und au 8er übertragen
```{r, echo=FALSE}
# clustering with optics
ops_reach2018 <- optics(bike_accidents2018)
ops_reach2018 <- extractDBSCAN(ops_reach2018, eps_cl = 450)
ops_reach2018
plot(ops_reach2018)
```

## clustered points 2018 data
```{r, echo=FALSE}
plot(bike_accidents2018, cex = 0.4, pch = 19, col = ops_reach2018$cluster + 1, asp = 1)
```

## Convex Cluster Hulls 2018 data
```{r, echo=FALSE}
hullplot(bike_accidents2018, ops_reach2018, asp = 1)
```

## Reachability Plot 2019 data
```{r, echo=FALSE}
# clustering with optics
ops_reach2019 <- optics(bike_accidents2019)
ops_reach2019 <- extractDBSCAN(ops_reach2019, eps_cl = 450)
ops_reach2019
plot(ops_reach2019)
```

## clustered points 2019 data
```{r, echo=FALSE}
plot(bike_accidents2019, cex = 0.4, pch = 19, col = ops_reach2019$cluster + 1, asp = 1)
```

## Convex Cluster Hulls 2019 data
```{r, echo=FALSE}
hullplot(bike_accidents2019, ops_reach2019, asp = 1)
```
:::

## Task 7
Discuss your results, including also limitations or problems, and possible other methods that you could have used.

KOMMENTAR 

# Second part: Polygon Delineation
## Task 8
Given the clusters that you have extracted in Part 1 of the DC1 assignment:

* a. Define a set of criteria that a method should fulfill that can be used to delineate the given clusters by polygons. Use free text for these definitions, but try to be concise and precise. (Note: These criteria can also be used in the subsequent Discussion to evaluate whether they have been met.)

KOMMENTAR

* b. Choose a polygon delineation method that you deem appropriate in light of the above
criteria. Justify your choice.

KOMMENTAR

## Task 9
From the years 2018 to 2021 for which you computed clusters in Task 6, choose at least two years and apply your polygon delineation method of choice to each of these two years separately. Compute the Jaccard Index (aka Intersection over Union) for pair(s) of selected years and present and discuss the results.

##da stimmt noch immer was mit dieser Intersection nicht -> Sarah

```{r , echo = FALSE}
# add cluster info to data
bike_acc2018_clus <- st_as_sf(as.data.frame(cbind(bike_accidents2018, ops_reach2018$cluster)), 
                              coords = c("X", "Y"), crs = 2056)
bike_acc2019_clus <- st_as_sf(as.data.frame(cbind(bike_accidents2019, ops_reach2019$cluster)), 
                              coords = c("X", "Y"), crs = 2056)

summary(bike_acc2018_clus) # for 2018 data, there are 3 clusters
summary(bike_acc2019_clus) # for 2019 data, there are 7 clusters

# separate data into single clusters

bike_acc2018_c1 <- bike_acc2018_clus |> 
  filter(V4 == 1)
bike_acc2018_c2 <- bike_acc2018_clus |> 
  filter(V4 == 2)
bike_acc2018_c3 <- bike_acc2018_clus |> 
  filter(V4 == 3)
#bike_acc2018_c4 <- bike_acc2018_clus |> 
  #filter(V4 == 4)
# bike_acc2018_c5 <- bike_acc2018_clus |> 
#   filter(V4 == 5)
# bike_acc2018_c6 <- bike_acc2018_clus |> 
#   filter(V4 == 6)
# bike_acc2018_c7 <- bike_acc2018_clus |> 
#   filter(V4 == 7)
# bike_acc2018_c8 <- bike_acc2018_clus |> 
#   filter(V4 == 8)

bike_acc2019_c1 <- bike_acc2019_clus |> 
  filter(V4 == 1)
bike_acc2019_c2 <- bike_acc2019_clus |> 
  filter(V4 == 2)
bike_acc2019_c3 <- bike_acc2019_clus |> 
  filter(V4 == 3)
bike_acc2019_c4 <- bike_acc2019_clus |> 
  filter(V4 == 4)
bike_acc2019_c5 <- bike_acc2019_clus |> 
  filter(V4 == 5)
bike_acc2019_c6 <- bike_acc2019_clus |> 
  filter(V4 == 6)
bike_acc2019_c7 <- bike_acc2019_clus |> 
  filter(V4 == 7)
# bike_acc2019_c8 <- bike_acc2019_clus |> 
#   filter(V4 == 8)
# bike_acc2019_c9 <- bike_acc2019_clus |> 
#   filter(V4 == 9)
# bike_acc2019_c10 <- bike_acc2019_clus |> 
#   filter(V4 == 10)

# compare thresholds
cave_acc2018_2 <- concaveman(bike_acc2018_c1, concavity = 2, length_threshold = 0)
cave_acc2018_1 <- concaveman(bike_acc2018_c1, concavity = 1, length_threshold = 0)
cave_acc2018_05 <- concaveman(bike_acc2018_c1, concavity = 0.5, length_threshold = 0)
```
::: {.panel-tabset .nav-pills}
# find best concavity value
```{r}
#ggplot() +
  # geom_sf(data = districts, color = "black", fill = NA) +
  # geom_sf(data=bike_acc2018_c1, size = 0.5) +
  # geom_sf(data = cave_acc2018_2, color = "cyan", fill = alpha("cyan", alpha=0.2)) +
  # geom_sf(data = cave_acc2018_1, color = "magenta", fill = alpha("magenta", alpha=0.2)) +
  # geom_sf(data = cave_acc2018_05, color = "yellow", fill = alpha("yellow", alpha=0.2)) +
  # coord_sf(datum = NA)+
  # ggtitle("find best concavity value")+
  # theme_minimal()

# 1 seems best value for concavity
bike_acc2018_c1_con <- concaveman(bike_acc2018_c1, concavity = 1, length_threshold = 0)
bike_acc2018_c2_con <- concaveman(bike_acc2018_c2, concavity = 1, length_threshold = 0)
bike_acc2018_c3_con <- concaveman(bike_acc2018_c3, concavity = 1, length_threshold = 0)
#bike_acc2018_c4_con <- concaveman(bike_acc2018_c4, concavity = 1, length_threshold = 0)
# bike_acc2018_c5_con <- concaveman(bike_acc2018_c5, concavity = 1, length_threshold = 0)
# bike_acc2018_c6_con <- concaveman(bike_acc2018_c6, concavity = 1, length_threshold = 0)
# bike_acc2018_c7_con <- concaveman(bike_acc2018_c7, concavity = 1, length_threshold = 0)
# bike_acc2018_c8_con <- concaveman(bike_acc2018_c8, concavity = 1, length_threshold = 0)

bike_acc2019_c1_con <- concaveman(bike_acc2019_c1, concavity = 1, length_threshold = 0)
bike_acc2019_c2_con <- concaveman(bike_acc2019_c2, concavity = 1, length_threshold = 0)
bike_acc2019_c3_con <- concaveman(bike_acc2019_c3, concavity = 1, length_threshold = 0)
bike_acc2019_c4_con <- concaveman(bike_acc2019_c4, concavity = 1, length_threshold = 0)
bike_acc2019_c5_con <- concaveman(bike_acc2019_c5, concavity = 1, length_threshold = 0)
bike_acc2019_c6_con <- concaveman(bike_acc2019_c6, concavity = 1, length_threshold = 0)
bike_acc2019_c7_con <- concaveman(bike_acc2019_c7, concavity = 1, length_threshold = 0)
# bike_acc2019_c8_con <- concaveman(bike_acc2019_c8, concavity = 1, length_threshold = 0)
# bike_acc2019_c9_con <- concaveman(bike_acc2019_c9, concavity = 1, length_threshold = 0)
# bike_acc2019_c10_con <- concaveman(bike_acc2019_c10, concavity = 1, length_threshold = 0)
```

# Clusters of bike accidents 2018
```{r}
ggplot() +
  geom_sf(data = districts, color = "black", fill = NA) +
  geom_sf(data = bike_acc2018_c1, color = "black", size = 0.5) +
  geom_sf(data = bike_acc2018_c1_con, color = "pink", fill = alpha("pink", alpha=0.3)) + 
  geom_sf(data = bike_acc2018_c2, color = "black", size = 0.5) +
  geom_sf(data = bike_acc2018_c2_con, color = "purple", fill = alpha("purple", alpha=0.3)) + 
  geom_sf(data = bike_acc2018_c3, color = "black", size = 0.5) +
  geom_sf(data = bike_acc2018_c3_con, color = "seagreen", fill = alpha("seagreen", alpha=0.3)) + 
  #geom_sf(data = bike_acc2018_c4, color = "black", size = 0.5) +
  #geom_sf(data = bike_acc2018_c4_con, color = "chartreuse", fill = alpha("chartreuse", alpha=0.3)) + 
  # geom_sf(data = bike_acc2018_c5, color = "black", size = 0.5) +
  # geom_sf(data = bike_acc2018_c5_con, color = "blue", fill = alpha("blue", alpha=0.3)) + 
  # geom_sf(data = bike_acc2018_c6, color = "black", size = 0.5) +
  # geom_sf(data = bike_acc2018_c6_con, color = "lightblue", fill = alpha("lightblue", alpha=0.3)) + 
  # geom_sf(data = bike_acc2018_c7, color = "black", size = 0.5) +
  # geom_sf(data = bike_acc2018_c7_con, color = "orange", fill = alpha("orange", alpha=0.3)) + 
  # geom_sf(data = bike_acc2018_c8, color = "black", size = 0.5) +
  # geom_sf(data = bike_acc2018_c8_con, color = "red", fill = alpha("red", alpha=0.3)) +
  theme_minimal() +
  coord_sf(datum = NA)
```

# Clusters of bike accidents 2019
#####Fehler Saskia fixen. Info von Sarah: CLuster 7 kann nicht geplottet werden, da es nur ein punkt ist
```{r}
ggplot() +
  geom_sf(data = districts, color = "black", fill = NA) +
  geom_sf(data = bike_acc2019_c1, color = "black", size = 0.5) +
  geom_sf(data = bike_acc2019_c1_con, color = "pink", fill = alpha("pink", alpha=0.3)) + 
  geom_sf(data = bike_acc2019_c2, color = "black", size = 0.5) +
  geom_sf(data = bike_acc2019_c2_con, color = "purple", fill = alpha("purple", alpha=0.3)) + 
  geom_sf(data = bike_acc2019_c3, color = "black", size = 0.5) +
  geom_sf(data = bike_acc2019_c3_con, color = "seagreen",  fill = alpha("seagreen", alpha=0.3)) + 
  geom_sf(data = bike_acc2019_c4, color = "black", size = 0.5) +
  geom_sf(data = bike_acc2019_c4_con, color = "chartreuse",fill = alpha("chartreuse", alpha=0.3)) + 
  geom_sf(data = bike_acc2019_c5, color = "black", size = 0.5) +
  geom_sf(data = bike_acc2019_c5_con, color = "blue", fill = alpha("blue", alpha=0.3)) + 
  geom_sf(data = bike_acc2019_c6, color = "black", size = 0.5) +
  geom_sf(data = bike_acc2019_c6_con, color = "lightblue",  fill = alpha("lightblue", alpha=0.3)) + 
  geom_sf(data = bike_acc2019_c7, color = "black", size = 0.5) +
  #geom_sf(data = bike_acc2019_c7_con, color = "orange", fill = alpha("orange", alpha=0.3))  + 
  # geom_sf(data = bike_acc2019_c8, color = "black", size = 0.5) +
  # geom_sf(data = bike_acc2019_c8_con, color = "red",  fill = alpha("red", alpha=0.3)) +
  # geom_sf(data = bike_acc2019_c9, color = "black", size = 0.5) +
  # geom_sf(data = bike_acc2019_c9_con, color = "gold",  fill = alpha("gold", alpha=0.3)) + 
  # geom_sf(data = bike_acc2019_c10, color = "black", size = 0.5) +
  # geom_sf(data = bike_acc2019_c10_con, color = "magenta",  fill = alpha("magenta", alpha=0.3))+
  theme_minimal() +
  coord_sf(datum = NA)
```

# Jaccard Index 
```{r}
# Compute the Jaccard Index
## unify single polygons from 2018 and 2019


pol18<- dplyr::bind_rows(list(bike_acc2018_c1_con, 
                     bike_acc2018_c2_con,bike_acc2018_c3_con))

pol19<- dplyr::bind_rows(list(bike_acc2019_c1_con, bike_acc2019_c2_con,
                     bike_acc2019_c3_con, bike_acc2019_c4_con,
                     bike_acc2019_c5_con, bike_acc2019_c6_con))

poly2018<-st_union(pol18)
poly2019<-st_union(pol19)


## compute difference
poly2018_2019_diff <- st_difference(poly2018, poly2019)
poly2019_2018_diff <- st_difference(poly2019, poly2018)
poly_18_19diff <- st_union(poly2018_2019_diff, poly2019_2018_diff)


plot(st_coordinates(poly2018), xlab = "Easting [m]", ylab = "Northing [m]", 
     type = "n", asp = 1)
plot(poly2018, col =alpha("cyan", 0.3), border = NA, add = TRUE)
plot(poly2019, col =alpha("magenta", 0.3) , border = NA, add = TRUE)
plot(poly_18_19diff, border = "purple", add = TRUE)

cat("Area of 2018:", sf::st_area(poly2018), "m^2 \n",
    "Area of 2019: ", sf::st_area(poly2019), "m^2 \n",
    "Difference Area:    ", sf::st_area(poly_18_19diff), "m^2 \n")
```
:::

KOMMENTAR

## Task 10
Overall, what did you find with the above steps? What do these steps tell you about the situation of bicycle accidents in Zurich? How useful are the methods used so far in analysing the given data? Any other points of note?

KOMMENTAR

# Third part: Density estimation
## Task 11
Similarly to the clustering and polygon delineation tasks carried out in Parts 1 and 2 of DC1, respectively, start off by defining criteria for using KDE to detect areas/hotspots of elevated bicycle accident density, and explain your reasoning.

KOMMENTAR

## Task 12
Choose any two years from the years 2018 to 2021 (justify your choice of years) and compute the KDE surfaces for each of these two separately and visualize your results. You are free to choose the KDE implementation (i.e., R package and function(s)) as well as the parameters (bandwidth selection method, etc.), but you should document your choices and discuss, in the subsequent Task 14, your results in light of your choices.
####
KOMMENTAR 
```{r}
 # get sf data for bike accidents in 2018 and 2019
bike_accidents_sf <- bike_accidents|> 
  filter(bike_accidents$AccidentInvolvingBicycle == "true")

bike_accidents_2018_sf <- bike_accidents_sf |> 
  filter(bike_accidents_sf$AccidentYear == 2018)
bike_accidents_2019_sf <- bike_accidents_sf |> 
  filter(bike_accidents_sf$AccidentYear == 2019)
# drop everything except geometry
bike_accidents_2018_og <- st_zm(bike_accidents_2018_sf[,22])
bike_accidents_2019_og <- st_zm(bike_accidents_2019_sf[,22])

# convert to SpatialPointsDataFrame
bike_acc2018_point <- as(bike_accidents_2018_og, "Spatial")
bike_acc2019_point <- as(bike_accidents_2019_og, "Spatial")

# get coordinates and drop Z
bike_acc2018_coords <- st_coordinates(bike_accidents_2018_sf)
bike_acc2019_coords <- st_coordinates(bike_accidents_2019_sf)
bike_acc2018_coords <- bike_acc2018_coords[,-3]
bike_acc2019_coords <- bike_acc2019_coords[,-3]

```

## Testing for normal distribution 
###Sarah LSCV adehabitat

```{r}
# polygon if an sfc/sf object of type POLYGON was used.
win_bike_18 <- spatstat.geom::as.owin(sf::st_bbox(bike_accidents_2018_sf))
bike_18_ppp <- spatstat.geom::ppp(x = bike_acc2018_coords[,1], y = bike_acc2018_coords[,2], window = win_bike_18)

teststats_18 <- quadrat.test(bike_18_ppp, nx = 10, ny = 10)


win_bike_19 <- spatstat.geom::as.owin(sf::st_bbox(bike_accidents_2019_sf))
bike_19_ppp <- spatstat.geom::ppp(x = bike_acc2019_coords[,1], y = bike_acc2019_coords[,2], window = win_bike_19)

teststats_19 <- quadrat.test(bike_19_ppp, nx = 10, ny = 10)
teststats_19

```
::: {.panel-tabset .nav-pills}
#Test for normal distribution 2018
```{r}
teststats_18
```

#Test for normal distribution 2019
```{r}
teststats_19
```




```{r}

bike_accidents_2018_sp <- as(bike_accidents_2018_sf, "Spatial")
bike_accidents_2019_sp <- as(bike_accidents_2019_sf, "Spatial")


bikes18_z<-st_zm(bike_accidents_2018_sf[,22])
bikes19_z<-st_zm(bike_accidents_2019_sf[,22])

bike_accidents_2018_sp <- as(bikes18_z, "Spatial")
bike_accidents_2019_sp<- as(bikes19_z, "Spatial")


#we adapt the percentage to the percentage of all points which was included in previous clustering to define the homerange
593+9+7#609
583+4+17+8+4+5#621

100/692*609#88.01
100/695*621#89.35
#to use a round number and try to make them more compatible we are using 88.5 to get a comparable area


ext_val <- 0.5   
grid_val <- 500   #use val from earlier calculation

#Apply LSCV
ud18 <- adehabitatHR::kernelUD(bike_accidents_2018_sp, grid = grid_val, extent = ext_val, h = "href")


hr95 <- adehabitatHR::getverticeshr(ud18, percent = 95) 
hr88.5 <- adehabitatHR::getverticeshr(ud18, percent = 88.5)  
hr75 <- adehabitatHR::getverticeshr(ud18, percent = 75)  

hr50 <- adehabitatHR::getverticeshr(ud18, percent = 50)   
graphics::image(ud18, xlab = "x [m]", ylab = "y [m]",
                col = hcl.colors(200, palette = "heat 2", rev = TRUE))
xmin <- min(ud18$ZH@coords[,1])
xmax <- max(ud18$ZH@coords[,1])
ymin <- min(ud18$ZH@coords[,2])
ymax <- max(ud18$ZH@coords[,2])
plot(hr50, lty = 1, lwd = 2, border = "black", add = TRUE, axes = FALSE)
plot(hr75, lty = 1, lwd = 2, border = "darkgreen", add = TRUE, axes = FALSE)
plot(hr88.5, lty = 1, lwd = 2, border = "red", add = TRUE, axes = FALSE)
plot(hr95, lty = 1, lwd = 2, border = "blue", add = TRUE, axes = FALSE)
axis(1)
axis(2, pos = xmin - 100)
text(xmin - 150, ymin + (ymax - ymin) / 2, "y [m]", 
     adj = c(NA, -4), srt = 90)
title("KDE with bandwidth selection method HREF", line = -0.3)
legend("topright", c("HR 50%", "HR 95%"), 
       col = c("black", "blue"), lwd = c(3, 2), lty = c(4, 1), 
       inset = c(0.19, 0.06), cex = 0.75)

```

::: {.panel-tabset .nav-pills}


# Unweighted KDE; plug-in bandwidth 2018 data
```{r}
# Plotting utilizes the specialized S3 plot.kde() function
plot(fkde18, display = "filled.contour2", 
     cont = c(10, 20, 30, 40, 50, 60, 70, 80, 90, 95, 100), asp = 1)
plot(bike_accidents_2018_sf, cex = 0.5, pch = 16, col = "black", add = TRUE)
```

# Unweighted KDE; plug-in bandwidth 2019 data
```{r}
plot(fkde19, display = "filled.contour2", 
     cont = c(10, 20, 30, 40, 50, 60, 70, 80, 90, 95, 100), asp = 1)
plot(bike_accidents_2019_sf, cex = 0.5, pch = 16, col = "black", add = TRUE)
```

# Unweighted KDE; least-squares cross validation bandwidth (LSCV) 2018 data
```{r}
h18_lscv <- ks::Hlscv(x = bike_acc2018_coords)
fkde18_lscv <- ks::kde(bike_acc2018_coords, H = h18_lscv)
plot(fkde18_lscv, display = "image", asp = 1)
plot(bike_accidents_2018_sf, cex = 0.5, pch = 16, col = "black", add = TRUE)
```

# Unweighted KDE; least-squares cross validation bandwidth (LSCV) 2019 data
```{r}
h19_lscv <- ks::Hlscv(x = bike_acc2019_coords)
fkde19_lscv <- ks::kde(bike_acc2019_coords, H = h19_lscv)
plot(fkde19_lscv, display = "image", asp = 1)
plot(bike_accidents_2019_sf, cex = 0.5, pch = 16, col = "black", add = TRUE)
```
:::

## Task 13
Compute the “volume of intersection” (“VI”) between the KDE surfaces (utilization distributions) of the two years. Hint: There are different ways to do that, but the adehabitatHR package has functionality for that. How do the results correspond to those of Task 9 (Jaccard Index or IoU)?
####Sarah VI berechnen
```{r}

kdepol18<- dplyr::bind_rows(list(bike_acc2018_c1_con, 
                     bike_acc2018_c2_con,bike_acc2018_c3_con))

kdepol19<- dplyr::bind_rows(list(bike_acc2019_c1_con, bike_acc2019_c2_con,
                     bike_acc2019_c3_con, bike_acc2019_c4_con,
                     bike_acc2019_c5_con, bike_acc2019_c6_con))

kdepoly2018<-st_union(kdepol18)
kdepoly2019<-st_union(kdepol19)


## compute difference
kdepoly2018_2019_diff <- st_difference(kdepoly2018, kdepoly2019)
kdepoly2019_2018_diff <- st_difference(kdepoly2019, kdepoly2018)
kdepoly_18_19diff <- st_union(kdepoly2018_2019_diff, kdepoly2019_2018_diff)


plot(st_coordinates(kdepoly2018), xlab = "Easting [m]", ylab = "Northing [m]", 
     type = "n", asp = 1)
plot(kdepoly2018, col =alpha("cyan", 0.3), border = NA, add = TRUE)
plot(kdepoly2019, col =alpha("magenta", 0.3) , border = NA, add = TRUE)
plot(kdepoly_18_19diff, border = "purple", add = TRUE)

cat("Area of 2018:", sf::st_area(poly2018), "m^2 \n",
    "Area of 2019: ", sf::st_area(poly2019), "m^2 \n",
    "Difference Area:    ", sf::st_area(poly_18_19diff), "m^2 \n")


```


KOMMENTAR

## Task 14
Discuss your results for this part of DC1 (density estimation). What did you find? Compare the results of this part with the clusters/polygons of Parts 1 and 2 (see note below): What are the commonalities? What are the differences? Which method(s) perform more adequately than others for the given problem and data? Which method(s) would you recommend, and which ones not? Why? (You are free to add more points to the discussion.)

KOMMENTAR

# Fourth part: Second Order Properties
## Task 15
Choose one or more distance measure functions (justify your choice) and compute it/them for

KOMMENTAR

* a. all bicycle accidents (2011 - 2021) 

* b. bicycle accidents for one of the years selected in Task 6 

* c. bicycle accidents for only the cluster points of the year selected in (b)

Restrict your analysis to the “inner city” and use the same window for all point sets. It’s up to you to define the extent of the “inner city” and explain/justify what that means in terms of this data challenge.



* c. bicycle accidents for only the cluster points of the year selected in (b)
Restrict your analysis to the “inner city” and use the same window for all point sets. It’s up to you to define the extent of the “inner city” and explain/justify what that means in terms of this data challenge.


##intersection
```{r}
districts145<-districts[10:12,]

dist145_2018<-st_intersection(filter(bike_accidents, AccidentYear ==2018),districts145)

ggplot()+
  geom_sf(data=boundary, aes(color="white"))+
  geom_sf(data=dist145_2018, aes(color="black"))+
  theme(legend.position="none")#looks good

```


::: {.panel-tabset .nav-pills}
## Choosing a subset of districts
```{r, echo=FALSE}
ggplot(districts)+
  geom_sf(aes(fill=KNR))+
  geom_sf_label(aes(label = KNAME))+
  theme_minimal() +
  coord_sf(datum = NA)+
  xlab("")+
  ylab("")
```

## L-Function 2018 data
```{r, echo=FALSE}
# Create a ppp object 

bike_accidents2018_coords145 <- sf::st_coordinates(dist145_2018)
win18_145 <- as.owin(st_bbox(dist145_2018))
bike_accidents2018_ppp_145 <- spatstat.geom::ppp(x = bike_accidents2018_coords145[,1], y =  bike_accidents2018_coords145[,2],
                        window = win18_145, unitname = c("meter", "meters"))

# Generate L-function
bike_accidents2018_enve145 <- spatstat.explore::envelope(bike_accidents2018_ppp_145, fun = Lest, nsim = 100, correction = "Ripley", verbose = FALSE)
# Plot 
plot(bike_accidents2018_enve145, main = "L-function of 2018 bike acccident points, with envelope for the districts 1,4 and 5")

```

## MAD & DCLF Test 2018 data
```{r, echo=FALSE}
# We also apply the MAD test
spatstat.explore::mad.test(bike_accidents2018_ppp_145, fun = Lest, nsim = 100, verbose = FALSE)
spatstat.explore::dclf.test(bike_accidents2018_ppp_145, fun = Lest, nsim = 100, verbose = TRUE)

```
:::
KOMMENTAR

## Task 16
Now choose the following two pairs of years, 2018 & 2019, as well as 2018 & 2021, and compute the cross-X function, where “X” stands for the function(s) you used in Task 15. Use the AccidentYear as the marks to produce a marked point pattern.


## Task 17
Discuss your results. Similarities and differences between the various point sets? Noteworthy spatial and/or temporal patterns? Is any difference observable in the patterns of the cross-X function in the transition to the Covid-19 pandemic? etc. etc. Note: Consider in your interpretation that the distance scale may change between years.

KOMMENTAR 

## Task 18
From the bicycle accidents data, choose at least two relevant variables that make sense being compared, e.g. two different accident types, severity levels, times of day, years etc. For these selected accidents, compute the counts within the ‘statistical zones’ of Zurich and use these counts to compute the Getis-Ord G*-statistic for each of your counts layers. Visualize your results appropriately.

```{r}
# read data of statistical zones
zh_stat_zone <- sf::st_read("Session_5/zh_stat_zones.gpkg")

nn_dis <- 450

getisbikedata<-filter(bike_accidents_sf, AccidentYear =="2018"| AccidentYear == "2019")[,c(24,38)]

# create list of euclidean neighbors with min. distance = 0 and max. distance = nn_dis 
bike_acc_nb <- spdep::dnearneigh(getisbikedata, 0, nn_dis)

# convert into list with spatial weights, B = binary weight
bike_acc_lw <- spdep::nb2listw(spdep::include.self(bike_acc_nb), style = "B")

# Create the line links from the nb object, requesting an sf object to be returned.
# CRS needs to be set as it was carried over to the nb object.
bike_acc_links <- 
   spdep::nb2lines(bike_acc_nb, coords = sf::st_geometry(getisbikedata), as_sf = TRUE) |>
   sf::st_set_crs(2056)
# 
# # Plot the neighbor links using functions from the tmap package
tmap::tm_shape(districts) + 
  tmap::tm_borders(col = "gray") +
  tmap::tm_shape(bike_acc_links) + 
  tmap::tm_lines(col = "red", lwd = 0.5) +
  tmap::tm_shape(getisbikedata) +
  tmap::tm_dots(col = "black", size = 0.1) +
  tmap::tm_scale_bar(position = c("right", "bottom"), width = 0.2)
   
```


```{r}
var_string <- c("2018", "2019")
variant <- c("2018", "2019")

# For each variant, compute local Gi*-statistic with spdep::localG() and 
# display as choropleth map.

# Define a function that, for a given variant, computes the local Gi*-statistic 
# with spdep::localG() and displays it as a choropleth map.
plot_variant <- function(i, j) {

# Create local Gi* stats object
sads_lG <-
    spdep::localG(x = as.numeric(unlist(getisbikedata[, i])), listw = bike_acc_lw)
  
  # attach Gi* statistic values to the sfc_POINT object
  s_lG <- sads_lG[1:length(sads_lG)]   # convert to vector
  tmp_sf <- bind_cols(getisbikedata, as.data.frame(s_lG))
  
  # generate map with dot symbols shaded according to Gi*-stats value
  m <- tmap::tm_shape(cantons_bound) +
    tmap::tm_borders(col = "gray") +
    tmap::tm_dots(
      size = 0.2,
      col = "s_lG",
      n = 6,
      midpoint = 0,
      palette = "-RdYlBu",
      title.size = 0.2,
      title = paste("Variant \"", variant[j], "\"", sep = "")
    ) +
    tmap::tm_layout(
      main.title = "Gi*-statistic for comparative clause",
      main.title.size = 1.0,
      main.title.fontface = "bold",
      main.title.position = c("left", "top"),
      legend.position = c("left", "top"),
      frame = FALSE,
      inner.margins = c(0.05, 0.05, 0.05, 0.05)
    ) +
    tmap::tm_scale_bar(position = c("right", "bottom"), width = 0.2)
  
  # a tmap inside a loop needs to be *printed* explicitly; otherwise it won't show
  # print(m)
  
  return(m)
}

```


::: {.panel-tabset .nav-pills}

### Variant "als"
```{r}
plot_variant("2018", 1)
```

### Variant "weder"
```{r}
plot_variant("prop_v2_weder", 2)
```

### Variant "wie"
```{r}
plot_variant("prop_v3_wie", 3)
```

### Variant "wan"
```{r}
plot_variant("prop_v4_wan", 4)
```

:::

####Hier fehlt noch was Sarah

## Task 19
Discuss your results. What did you find regarding the hot and cold spots in your accident count layers? How do they compare to each other across layers and across (past) methods? etc. Discuss also the influence of the parameter settings (e.g., neighbor search distance, spatial weight formation) on your results.

KOMMENTAR


