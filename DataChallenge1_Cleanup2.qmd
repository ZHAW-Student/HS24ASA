---
title: "Data Challenge 1"
author: "Saskia Gianola / Sarah Wirth"
date: "October/November 2024"
format: 
  html:
    embed-resources: true
    fig_caption: true
    fig-align: center
    highlight: tango
    number-sections: false
    theme: journal
    toc: true
    toc_depth: 2
    toc_float: true
execute:                      # Set global options for execution of code blocks
  echo: false
  warning: false
  message: false
---
# Introduction
This file includes the assignments, code and interpretation of Data Challenge 1. The code was elaborated as collaboration between Sarah Wirth and Saskia Gianola. For this work no language models like ChatGPT have been used (neither for the code nor the text answers). We are aware about you not grading the code but still invite you to take a look at it, as we spent quite some time struggling with it. 

```{r}
#Packages
library(dplyr)
library(tidyr)
library(ggplot2)
library(lubridate)
library(sf)
library(cluster)
library(dbscan)
library(fpc)
library(concaveman)
library(adehabitatHR)
library(spatstat)
library(spdep)
library(ks)

```

# First part: Spatial Clustering
## Task 1
Download and import the road accident data from Open Data Zurich (ODZ) using an appropriate file format. If needed, transform to the Swiss projected CH1903+/LV95 coordinate system (EPSG = 2056).

```{r, echo=TRUE, , results='hide'}
accidents <- st_read("Session2/roadtrafficaccidentlocations.gpkg")
boundary <-st_read("Session2/Zurich_city_boundary_2024.gpkg")
districts <-st_read("Session2/Zurich_city_districts_2024.gpkg")
```
As all three layers are already in the Swiss projected CH1903+/LV95, there is no need for transformation. 

## Task 2
Report the following numbers in table(s):
  
```{r}
accidents_no_geom <- st_drop_geometry(accidents) # drop geometry to make code more efficient

acc_sever <- accidents_no_geom |> 
   count(AccidentSeverityCategory_en)

acc_type <- accidents_no_geom |> 
  count(AccidentType_en)

acc_ped <- accidents_no_geom |> 
  count(AccidentInvolvingPedestrian)

acc_bike <- accidents_no_geom |> 
  count(AccidentInvolvingBicycle)

acc_moto <- accidents_no_geom |> 
  count(AccidentInvolvingMotorcycle)

acc_ped_moto <- accidents_no_geom |> 
  count(AccidentInvolvingPedestrian, AccidentInvolvingMotorcycle)

acc_ped_bike <- accidents_no_geom |> 
  count(AccidentInvolvingPedestrian, AccidentInvolvingBicycle)

acc_moto_bike <- accidents_no_geom |> 
  count(AccidentInvolvingMotorcycle, AccidentInvolvingBicycle)

acc_ped_bike_moto <- accidents_no_geom |> 
  count(AccidentInvolvingPedestrian, AccidentInvolvingBicycle, AccidentInvolvingMotorcycle)
  
```
* a. Number of accidents by accident severity category
  
```{r}
acc_sever
```
  
* b. Number of accidents by accident type
  
```{r}
acc_type
```

* c. Number of accidents involving pedestrians, bicycles, and motorcycles, respectively. And combinations thereof (pedestrian AND bicycle, pedestrian AND motorcycle etc.). Are there any accidents involving all three modes (pedestrian, bicycle, motorcycle)?
  
```{r}
acc_ped
acc_bike
acc_moto
acc_ped_bike
acc_ped_moto
acc_moto_bike
acc_ped_bike_moto
```

## Task 3
Generate a plot showing the temporal evolution of the number of accidents from 2011 to 2023. Label each year with the corresponding number of accidents. Choose a plot type that is suitable for this type of temporal data. Bonus: Show also the data for the bicycle accidents (cf. Task 4) in the same plot.

```{r, echo=FALSE}
numyearbi <- accidents |> group_by(AccidentYear, AccidentInvolvingBicycle) |>
  summarise(n=n())
numyear <- numyearbi |> group_by(AccidentYear)  |> 
  summarise(n=n())
  

ggplot(numyearbi, aes(x=AccidentYear, y=n,fill=AccidentInvolvingBicycle, label=n)) +
  geom_bar(position="stack", stat="identity")+
  geom_text(size = 3, position = position_stack(vjust = 0.5)) +
  ylab("Total number of accidents") +
  xlab("Year") +
  theme_bw()+
  guides(fill=guide_legend(title="Accident involves bicycles"))

```

## Task 4
Select only those accidents that involved a bicycle. **From now on, and for the remainder of DC1, we will restrict our analysis to the accidents involving bicycles.** With this subset, produce a map showing the bicycle accident data colored by accident severity category. Use a basemap such as OpenStreetMap and/or the boundary data available on OLAT, so the accidents can be visually and spatially referenced.

::: {.panel-tabset .nav-pills}

# all bike accidents
```{r, echo=FALSE}
bike_accidents <- accidents |> 
  filter(AccidentInvolvingBicycle == "true")


#Version normal
ggplot() +
  geom_sf(data = bike_accidents, mapping = aes(color = AccidentSeverityCategory)) +
  geom_sf(data = districts, color = "black", fill = NA) +
  coord_sf(datum = NA)+
  theme(legend.position = "bottom", panel.grid.major = element_line(colour = "transparent")) +
  theme_minimal()+
  scale_color_manual(values = c("red","orange2",  "gold", "blue"),
                               name = "Accident Severity",
                               breaks = c("as1",  "as3","as2", "as4"),
                               labels = c("fatalities", 
                                          "severe injuries",
                                          "light injuries",
                                          "property damage"))
#Version with alpha
# ggplot() +
#   geom_sf(data = bike_accidents, mapping = aes(color =AccidentSeverityCategory)) +
#   geom_sf(data = districts, color = "black", fill = NA, ) +
#   coord_sf(datum = NA)+
#   theme(legend.position = "bottom", panel.grid.major = element_line(colour = "transparent")) +
#   theme_minimal()+
#   scale_color_manual(values = c(alpha("red",alpha = 1.0), alpha("orange2",alpha = 0.8), alpha("gold",alpha = 0.8), alpha("blue",alpha = 0.8)),
#                                name = "Accident Severity",
#                                breaks = c("as1",  "as3","as2", "as4"),
#                                labels = c("fatalities", 
#                                           "severe injuries",
#                                           "light injuries",
#                                           "property damage"))
# 
# #Version with small multiples
# ggplot() +
#   geom_sf(data = bike_accidents, mapping = aes(color = AccidentSeverityCategory)) +
#   geom_sf(data = districts, color = "black", fill = NA) +
#   facet_wrap(~AccidentSeverityCategory)+
#   coord_sf(datum = NA)+
#   theme(legend.position = "bottom", panel.grid.major = element_line(colour = "transparent")) +
#   theme_minimal()+
#   theme(strip.text = element_blank())+
#   scale_color_manual(values = c("red","orange2",  "gold", "blue"),
#                                name = "Accident Severity",
#                                breaks = c("as1",  "as3","as2", "as4"),
#                                labels = c("fatalities", 
#                                           "severe injuries",
#                                           "light injuries",
#                                           "property damage"))
```
# bike accidents with fatalities
```{r}
bike_accidents_fatal <- bike_accidents |> 
  filter(AccidentSeverityCategory == "as1")

ggplot() +
  geom_sf(data = bike_accidents_fatal, color = "red") +
  geom_sf(data = districts, color = "black", fill = NA, ) +
  coord_sf(datum = NA)+
  theme_minimal()
```
# bike accidents with severe injuries
```{r}
bike_accidents_severe <- bike_accidents |> 
  filter(AccidentSeverityCategory == "as2")

ggplot() +
  geom_sf(data = bike_accidents_severe, color = "orange2") +
  geom_sf(data = districts, color = "black", fill = NA, ) +
  coord_sf(datum = NA)+
  theme_minimal()
```
# bike accidents with light injuries
```{r}
bike_accidents_light <- bike_accidents |> 
  filter(AccidentSeverityCategory == "as3")

ggplot() +
  geom_sf(data = bike_accidents_light, color = "gold") +
  geom_sf(data = districts, color = "black", fill = NA, ) +
  coord_sf(datum = NA)+
  theme_minimal()
```
# bike accidents with property damage
```{r}
bike_accidents_damage <- bike_accidents |> 
  filter(AccidentSeverityCategory == "as4")

ggplot() +
  geom_sf(data = bike_accidents_damage, color = "blue") +
  geom_sf(data = districts, color = "black", fill = NA, ) +
  coord_sf(datum = NA)+
  theme_minimal()
```
::: 

## Task 5 
Imagine you are given the task of detecting spatial clusters of elevated bicycle accident occurrence (without considering their severity). How would you characterize such "bicycle accident clusters"? Try to define properties that can be used to describe and identify such clusters, and that can be used to choose and parameterize a clustering method suitable for the task. Try to use natural, but precise and concise language in your answer.

KOMMENTAR


## Task 6
From the bicycle accidents, extract the years 2018 to 2021 and compute clusters for each year separately, using a clustering method you deem appropriate for the task, and choose the control parameters appropriately to capture the types of clusters you had in mind in your definition of Task 5. Justify your choice.


####Hier haben wir ne frage zur reihenfolge
```{r, echo=FALSE}
bike_accidents2018 <- st_coordinates(bike_accidents |> 
  filter(AccidentYear == "2018"))
bike_accidents2019 <- st_coordinates(bike_accidents |> 
  filter(AccidentYear == "2019"))
bike_accidents2020 <- st_coordinates(bike_accidents |> 
  filter(AccidentYear == "2020"))
bike_accidents2021 <- st_coordinates(bike_accidents |> 
  filter(AccidentYear == "2021"))
```

```{r, echo=FALSE}
# 2018 clustering with optics
ops_reach2018 <- optics(bike_accidents2018, minPts = 5)
ops_reach2018 <- extractDBSCAN(ops_reach2018, eps_cl = 500)
# ops_reach2018

# 2019 clustering with optics
ops_reach2019 <- optics(bike_accidents2019, minPts = 5)
ops_reach2019 <- extractDBSCAN(ops_reach2019, eps_cl = 500)
# ops_reach2019

# 2020 clustering with optics
ops_reach2020 <- optics(bike_accidents2020, minPts = 5)
ops_reach2020 <- extractDBSCAN(ops_reach2020, eps_cl = 500)
# ops_reach2020

# 2021 clustering with optics
ops_reach2021 <- optics(bike_accidents2021, minPts = 5)
ops_reach2021 <- extractDBSCAN(ops_reach2021, eps_cl = 500)
# ops_reach2021
```

::: {.panel-tabset .nav-pills}
## reachability plot 2018 data
```{r, echo=FALSE}
plot(ops_reach2018)
```

## clustered points 2018 data
```{r, echo=FALSE}
plot(bike_accidents2018, cex = 0.4, pch = 19, col = ops_reach2018$cluster + 1, asp = 1)
```

## reachability plot 2019 data
```{r, echo=FALSE}
plot(ops_reach2019)
```

## clustered points 2019 data
```{r, echo=FALSE}
plot(bike_accidents2019, cex = 0.4, pch = 19, col = ops_reach2019$cluster + 1, asp = 1)
```

## reachability Plot 2020 data
```{r, echo=FALSE}
plot(ops_reach2020)
```

## clustered points 2020 data
```{r, echo=FALSE}
plot(bike_accidents2020, cex = 0.4, pch = 19, col = ops_reach2020$cluster + 1, asp = 1)
```

## reachability plot 2021 data
```{r, echo=FALSE}
plot(ops_reach2021)
```

## clustered points 2021 data
```{r, echo=FALSE}
plot(bike_accidents2021, cex = 0.4, pch = 19, col = ops_reach2021$cluster + 1, asp = 1)
```
:::




```{r, echo=FALSE}
## cluster hulls 2018 data
# hullplot(bike_accidents2018[,c(1,2)], ops_reach2018, asp = 1, main = NA)
```


```{r, echo=FALSE}
## cluster hulls 2019 data
# hullplot(bike_accidents2019[,c(1,2)], ops_reach2019, asp = 1, main = NA)
```


```{r, echo=FALSE}
## cluster hulls 2020 data
# hullplot(bike_accidents2020[,c(1,2)], ops_reach2020, asp = 1, main = NA)
```


```{r, echo=FALSE}
# ## cluster hulls 2021 data
# hullplot(bike_accidents2021[,c(1,2)], ops_reach2021, asp = 1, main = NA)
```


## Task 7
Discuss your results, including also limitations or problems, and possible other methods that you could have used.

KOMMENTAR 



# Second part: Polygon Delineation
## Task 8
Given the clusters that you have extracted in Part 1 of the DC1 assignment:

* a. Define a set of criteria that a method should fulfill that can be used to delineate the given clusters by polygons. Use free text for these definitions, but try to be concise and precise. (Note: These criteria can also be used in the subsequent Discussion to evaluate whether they have been met.)

KOMMENTAR

* b. Choose a polygon delineation method that you deem appropriate in light of the above
criteria. Justify your choice.

KOMMENTAR



## Task 9
From the years 2018 to 2021 for which you computed clusters in Task 6, choose at least two years and apply your polygon delineation method of choice to each of these two years separately. Compute the Jaccard Index (aka Intersection over Union) for pair(s) of selected years and present and discuss the results.

```{r , echo = FALSE}
# add cluster info to data
bike_acc2018_clus <- st_as_sf(as.data.frame(cbind(bike_accidents2018, ops_reach2018$cluster)), 
                              coords = c("X", "Y"), crs = 2056)
bike_acc2019_clus <- st_as_sf(as.data.frame(cbind(bike_accidents2019, ops_reach2019$cluster)), 
                              coords = c("X", "Y"), crs = 2056)

# summary(bike_acc2018_clus) # for 2018 data, there are 4 clusters
# summary(bike_acc2019_clus) # for 2019 data, there are 7 clusters

# separate data into single clusters

bike_acc2018_c1 <- bike_acc2018_clus |> 
  filter(V4 == 1)
bike_acc2018_c2 <- bike_acc2018_clus |> 
  filter(V4 == 2)
bike_acc2018_c3 <- bike_acc2018_clus |> 
  filter(V4 == 3)
bike_acc2018_c4 <- bike_acc2018_clus |> 
  filter(V4 == 4)
#  bike_acc2018_c5 <- bike_acc2018_clus |> 
#    filter(V4 == 5)
#  bike_acc2018_c6 <- bike_acc2018_clus |> 
#    filter(V4 == 6)
#  bike_acc2018_c7 <- bike_acc2018_clus |> 
#    filter(V4 == 7)
#  bike_acc2018_c8 <- bike_acc2018_clus |> 
#    filter(V4 == 8)
# bike_acc2018_c9 <- bike_acc2018_clus |> 
#    filter(V4 == 9)
# bike_acc2018_c10 <- bike_acc2018_clus |> 
#    filter(V4 == 10)  
# bike_acc2018_c11 <- bike_acc2018_clus |> 
#    filter(V4 == 11)
#  bike_acc2018_c12 <- bike_acc2018_clus |> 
#    filter(V4 == 12)


bike_acc2019_c1 <- bike_acc2019_clus |> 
  filter(V4 == 1)
bike_acc2019_c2 <- bike_acc2019_clus |> 
  filter(V4 == 2)
bike_acc2019_c3 <- bike_acc2019_clus |> 
  filter(V4 == 3)
bike_acc2019_c4 <- bike_acc2019_clus |> 
  filter(V4 == 4)
bike_acc2019_c5 <- bike_acc2019_clus |> 
  filter(V4 == 5)
bike_acc2019_c6 <- bike_acc2019_clus |> 
  filter(V4 == 6)
bike_acc2019_c7 <- bike_acc2019_clus |> 
  filter(V4 == 7)
# bike_acc2019_c8 <- bike_acc2019_clus |> 
#    filter(V4 == 8)
# bike_acc2019_c9 <- bike_acc2019_clus |> 
#    filter(V4 == 9)
# bike_acc2019_c10 <- bike_acc2019_clus |> 
#    filter(V4 == 10)
# bike_acc2019_c11 <- bike_acc2019_clus |> 
#    filter(V4 == 11)
# bike_acc2019_c12 <- bike_acc2019_clus |> 
#    filter(V4 == 12)
# bike_acc2019_c13 <- bike_acc2019_clus |> 
#    filter(V4 == 13)


```

```{r}
# compare thresholds
cave_acc2018_2 <- concaveman(bike_acc2018_c1, concavity = 2, length_threshold = 0)
cave_acc2018_1 <- concaveman(bike_acc2018_c1, concavity = 1, length_threshold = 0)
cave_acc2018_05 <- concaveman(bike_acc2018_c1, concavity = 0.5, length_threshold = 0) 

#Compare concavity values
#ggplot() +
  # geom_sf(data = districts, color = "black", fill = NA) +
  # geom_sf(data=bike_acc2018_c1, size = 0.5) +
  # geom_sf(data = cave_acc2018_2, color = "cyan", fill = alpha("cyan", alpha=0.2)) +
  # geom_sf(data = cave_acc2018_1, color = "magenta", fill = alpha("magenta", alpha=0.2)) +
  # geom_sf(data = cave_acc2018_05, color = "yellow", fill = alpha("yellow", alpha=0.2)) +
  # coord_sf(datum = NA)+
  # ggtitle("find best concavity value")+
  # theme_minimal()

# 1 seems best value for concavity
```


```{r}
bike_acc2018_c1_con <- concaveman(bike_acc2018_c1, concavity = 1, length_threshold = 0)
bike_acc2018_c2_con <- concaveman(bike_acc2018_c2, concavity = 1, length_threshold = 0)
bike_acc2018_c3_con <- concaveman(bike_acc2018_c3, concavity = 1, length_threshold = 0)
bike_acc2018_c4_con <- concaveman(bike_acc2018_c4, concavity = 1, length_threshold = 0)
#  bike_acc2018_c5_con <- concaveman(bike_acc2018_c5, concavity = 1, length_threshold = 0)
#  bike_acc2018_c6_con <- concaveman(bike_acc2018_c6, concavity = 1, length_threshold = 0)
#  bike_acc2018_c7_con <- concaveman(bike_acc2018_c7, concavity = 1, length_threshold = 0)
# bike_acc2018_c8_con <- concaveman(bike_acc2018_c8, concavity = 1, length_threshold = 0)
# bike_acc2018_c9_con <- concaveman(bike_acc2018_c9, concavity = 1, length_threshold = 0)
# bike_acc2018_c10_con <- concaveman(bike_acc2018_c10, concavity = 1, length_threshold = 0)
# bike_acc2018_c11_con <- concaveman(bike_acc2018_c11, concavity = 1, length_threshold = 0)
# bike_acc2018_c12_con <- concaveman(bike_acc2018_c12, concavity = 1, length_threshold = 0)


bike_acc2019_c1_con <- concaveman(bike_acc2019_c1, concavity = 1, length_threshold = 0)
bike_acc2019_c2_con <- concaveman(bike_acc2019_c2, concavity = 1, length_threshold = 0)
bike_acc2019_c3_con <- concaveman(bike_acc2019_c3, concavity = 1, length_threshold = 0)
bike_acc2019_c4_con <- concaveman(bike_acc2019_c4, concavity = 1, length_threshold = 0)
bike_acc2019_c5_con <- concaveman(bike_acc2019_c5, concavity = 1, length_threshold = 0)
bike_acc2019_c6_con <- concaveman(bike_acc2019_c6, concavity = 1, length_threshold = 0)
bike_acc2019_c7_con <- concaveman(bike_acc2019_c7, concavity = 1, length_threshold = 0)
# bike_acc2019_c8_con <- concaveman(bike_acc2019_c8, concavity = 1, length_threshold = 0)
# bike_acc2019_c9_con <- concaveman(bike_acc2019_c9, concavity = 1, length_threshold = 0)
# bike_acc2019_c10_con <- concaveman(bike_acc2019_c10, concavity = 1, length_threshold = 0)
# bike_acc2019_c11_con <- concaveman(bike_acc2019_c11, concavity = 1, length_threshold = 0)
# bike_acc2019_c12_con <- concaveman(bike_acc2019_c12, concavity = 1, length_threshold = 0)
# bike_acc2019_c13_con <- concaveman(bike_acc2019_c13, concavity = 1, length_threshold = 0)

```
::: {.panel-tabset .nav-pills}
## clusters of bike accidents 2018
```{r}
ggplot() +
  geom_sf(data = districts, color = "black", fill = NA) +
  geom_sf(data = bike_acc2018_c1, color = "black", size = 0.5) +
  geom_sf(data = bike_acc2018_c1_con, color = "pink", fill = alpha("pink", alpha=0.3)) + 
  geom_sf(data = bike_acc2018_c2, color = "black", size = 0.5) +
  geom_sf(data = bike_acc2018_c2_con, color = "purple", fill = alpha("purple", alpha=0.3)) + 
  geom_sf(data = bike_acc2018_c3, color = "black", size = 0.5) +
  geom_sf(data = bike_acc2018_c3_con, color = "seagreen", fill = alpha("seagreen", alpha=0.3)) + 
  geom_sf(data = bike_acc2018_c4, color = "black", size = 0.5) +
  geom_sf(data = bike_acc2018_c4_con, color = "chartreuse", fill = alpha("chartreuse", alpha=0.3)) + 
  #  geom_sf(data = bike_acc2018_c5, color = "black", size = 0.5) +
  #  geom_sf(data = bike_acc2018_c5_con, color = "blue", fill = alpha("blue", alpha=0.3)) + 
  # geom_sf(data = bike_acc2018_c6, color = "black", size = 0.5) +
  # geom_sf(data = bike_acc2018_c6_con, color = "lightblue", fill = alpha("lightblue", alpha=0.3)) + 
  # geom_sf(data = bike_acc2018_c7, color = "black", size = 0.5) +
  # geom_sf(data = bike_acc2018_c7_con, color = "orange", fill = alpha("orange", alpha=0.3)) + 
  # geom_sf(data = bike_acc2018_c8, color = "black", size = 0.5) +
  # geom_sf(data = bike_acc2018_c8_con, color = "red", fill = alpha("red", alpha=0.3)) +
  # geom_sf(data = bike_acc2018_c9, color = "black", size = 0.5) +
  # geom_sf(data = bike_acc2018_c9_con, color = "palevioletred2", fill = alpha("palevioletred2", alpha=0.3)) +
  # geom_sf(data = bike_acc2018_c10, color = "black", size = 0.5) +
  # geom_sf(data = bike_acc2018_c10_con, color = "khaki2", fill = alpha("khaki2", alpha=0.3)) +
  # geom_sf(data = bike_acc2018_c11, color = "black", size = 0.5) +
  # geom_sf(data = bike_acc2018_c11_con, color = "darkseagreen2", fill = alpha("darkseagreen2", alpha=0.3)) +
  # geom_sf(data = bike_acc2018_c12, color = "black", size = 0.5) +
  # geom_sf(data = bike_acc2018_c12_con, color = "mediumspringgreen", fill = alpha("mediumspringgreen", alpha=0.3)) +
  theme_minimal() +
  coord_sf(datum = NA)
```

## clusters of bike accidents 2019
```{r}

##remove clusters consisting of two points somehow
ggplot() +
  geom_sf(data = districts, color = "black", fill = NA) +
  geom_sf(data = bike_acc2019_c1, color = "black", size = 0.5) +
  geom_sf(data = bike_acc2019_c1_con, color = "pink", fill = alpha("pink", alpha=0.3)) + 
  geom_sf(data = bike_acc2019_c2, color = "black", size = 0.5) +
  geom_sf(data = bike_acc2019_c2_con, color = "purple", fill = alpha("purple", alpha=0.3)) + 
  geom_sf(data = bike_acc2019_c3, color = "black", size = 0.5) +
  geom_sf(data = bike_acc2019_c3_con, color = "seagreen",  fill = alpha("seagreen", alpha=0.3)) + 
  geom_sf(data = bike_acc2019_c4, color = "black", size = 0.5) +
  geom_sf(data = bike_acc2019_c4_con, color = "chartreuse",fill = alpha("chartreuse", alpha=0.3)) + 
  geom_sf(data = bike_acc2019_c5, color = "black", size = 0.5) +
  geom_sf(data = bike_acc2019_c5_con, color = "blue", fill = alpha("blue", alpha=0.3)) + 
  geom_sf(data = bike_acc2019_c6, color = "black", size = 0.5) +
  geom_sf(data = bike_acc2019_c6_con, color = "lightblue",  fill = alpha("lightblue", alpha=0.3)) + 
  geom_sf(data = bike_acc2019_c7, color = "black", size = 0.5) +
  geom_sf(data = bike_acc2019_c7_con, color = "orange", fill = alpha("orange", alpha=0.3))  + 
  # geom_sf(data = bike_acc2019_c8, color = "black", size = 0.5) +
  # geom_sf(data = bike_acc2019_c8_con, color = "red",  fill = alpha("red", alpha=0.3)) +
  # geom_sf(data = bike_acc2019_c9, color = "black", size = 0.5) +
  # geom_sf(data = bike_acc2019_c9_con, color = "gold",  fill = alpha("gold", alpha=0.3)) + 
  # geom_sf(data = bike_acc2019_c10, color = "black", size = 0.5) +
  # geom_sf(data = bike_acc2019_c10_con, color = "magenta",  fill = alpha("magenta", alpha=0.3))+
  # geom_sf(data = bike_acc2019_c11, color = "black", size = 0.5) +
  # geom_sf(data = bike_acc2019_c11_con, color = "darkseagreen2", fill = alpha("darkseagreen2", alpha=0.3)) +
  # # geom_sf(data = bike_acc2019_c12, color = "black", size = 0.5) +
  # # geom_sf(data = bike_acc2019_c12_con, color = "mediumspringgreen", fill = alpha("mediumspringgreen", alpha=0.3)) +
  # geom_sf(data = bike_acc2019_c13, color = "black", size = 0.5) +
  # geom_sf(data = bike_acc2019_c13_con, color = "khaki2", fill = alpha("khaki2", alpha=0.3)) +
  theme_minimal() +
  coord_sf(datum = NA)
```

##overlap of areas 
```{r}
# Compute the Jaccard Index
## unify single polygons from 2018 and 2019


pol18<- dplyr::bind_rows(list(bike_acc2018_c1_con, 
                     bike_acc2018_c2_con,bike_acc2018_c3_con))

pol19<- dplyr::bind_rows(list(bike_acc2019_c1_con, bike_acc2019_c2_con,
                     bike_acc2019_c3_con, bike_acc2019_c4_con,
                     bike_acc2019_c5_con, bike_acc2019_c6_con))

poly2018<-st_union(pol18)
poly2019<-st_union(pol19)


## compute intersection and union
poly_18_19inters<- st_intersection(poly2019, poly2018)
poly_18_19union<- st_union(poly2019, poly2018)


plot(st_coordinates(poly2018), xlab = "Easting [m]", ylab = "Northing [m]", 
     type = "n", asp = 1)
plot(poly2018, col =alpha("cyan", 0.3), border = NA, add = TRUE)
plot(poly2019, col =alpha("magenta", 0.3) , border = NA, add = TRUE)
legend("bottomleft", legend=c("area 2018", "area 2019"),
       fill=c("cyan", "magenta"), cex=0.8)

```

##Jaccard Index
```{r}
cat("Area of 2018:", sf::st_area(poly2018), "m^2 \n",
    "Area of 2019:", sf::st_area(poly2019), "m^2 \n",
    "Intersection Area:",sf::st_area(poly_18_19inters), "m^2 \n",
    "Union Area:", sf::st_area(poly_18_19union), "m^2 \n",
    "Jaccard Index:", sf::st_area(poly_18_19inters)/sf::st_area(poly_18_19union),  "\n")
```
:::

KOMMENTAR

## Task 10
Overall, what did you find with the above steps? What do these steps tell you about the situation of bicycle accidents in Zurich? How useful are the methods used so far in analysing the given data? Any other points of note?

KOMMENTAR

# Third part: Density estimation
## Task 11
Similarly to the clustering and polygon delineation tasks carried out in Parts 1 and 2 of DC1, respectively, start off by defining criteria for using KDE to detect areas/hotspots of elevated bicycle accident density, and explain your reasoning.

KOMMENTAR

## Task 12
Choose any two years from the years 2018 to 2021 (justify your choice of years) and compute the KDE surfaces for each of these two separately and visualize your results. You are free to choose the KDE implementation (i.e., R package and function(s)) as well as the parameters (bandwidth selection method, etc.), but you should document your choices and discuss, in the subsequent Task 14, your results in light of your choices.

KOMMENTAR 

```{r}
 # get sf data for bike accidents in 2018 and 2019
bike_accidents_sf <- bike_accidents|> 
  filter(bike_accidents$AccidentInvolvingBicycle == "true")

bike_accidents_2018_sf <- bike_accidents_sf |> 
  filter(bike_accidents_sf$AccidentYear == 2018)
bike_accidents_2019_sf <- bike_accidents_sf |> 
  filter(bike_accidents_sf$AccidentYear == 2019)
# drop everything except geometry
bike_accidents_2018_og <- st_zm(bike_accidents_2018_sf[,22])
bike_accidents_2019_og <- st_zm(bike_accidents_2019_sf[,22])

# convert to SpatialPointsDataFrame
bike_acc2018_point <- as(bike_accidents_2018_og, "Spatial")
bike_acc2019_point <- as(bike_accidents_2019_og, "Spatial")

# get coordinates and drop Z
bike_acc2018_coords <- st_coordinates(bike_accidents_2018_sf)
bike_acc2019_coords <- st_coordinates(bike_accidents_2019_sf)
bike_acc2018_coords <- bike_acc2018_coords[,-3]
bike_acc2019_coords <- bike_acc2019_coords[,-3]

```


```{r}
## Testing for normal distribution 
# polygon if an sfc/sf object of type POLYGON was used.
win_bike_18 <- spatstat.geom::as.owin(sf::st_bbox(bike_accidents_2018_sf))
bike_18_ppp <- spatstat.geom::ppp(x = bike_acc2018_coords[,1], y = bike_acc2018_coords[,2], window = win_bike_18)

teststats_18 <- quadrat.test(bike_18_ppp, nx = 10, ny = 10)


win_bike_19 <- spatstat.geom::as.owin(sf::st_bbox(bike_accidents_2019_sf))
bike_19_ppp <- spatstat.geom::ppp(x = bike_acc2019_coords[,1], y = bike_acc2019_coords[,2], window = win_bike_19)

teststats_19 <- quadrat.test(bike_19_ppp, nx = 10, ny = 10)

```

::: {.panel-tabset .nav-pills}
##Test for normal distribution 2018
```{r}
teststats_18
```

##Test for normal distribution 2019
```{r}
teststats_19
```

:::


```{r}
bike_accidents_2018_sp <- as(bike_accidents_2018_sf, "Spatial")
bike_accidents_2019_sp <- as(bike_accidents_2019_sf, "Spatial")


bikes18_z<-st_zm(bike_accidents_2018_sf[,22])
bikes19_z<-st_zm(bike_accidents_2019_sf[,22])

bike_accidents_2018_sp <- as(bikes18_z, "Spatial")
bike_accidents_2019_sp<- as(bikes19_z, "Spatial")


#we adapt the percentage to the percentage of all points which was included in previous clustering to define the homerange
# 609+6+4+9#628
# 594+12+18+8+4+5+4#645
# 
# 100/692*628#90.75
# 100/695*645#92.81
#to use a round number and try to make them more compatible we are using 90 to get a comparable area


ext_val <- 0.5   
grid_val <- 500   #use val from earlier calculation

ud18 <- adehabitatHR::kernelUD(bike_accidents_2018_sp, grid = grid_val, extent = ext_val, h = "href")
ud19 <- adehabitatHR::kernelUD(bike_accidents_2019_sp, grid = grid_val, extent = ext_val, h = "href")

hr18_90 <- adehabitatHR::getverticeshr(ud18, percent = 90)  
hr19_90 <- adehabitatHR::getverticeshr(ud19, percent = 90)  

```

###Generating KDE



```{r}
xmin19 <- min(ud19$ZH@coords[,1])
xmax19 <- max(ud19$ZH@coords[,1])
ymin19 <- min(ud19$ZH@coords[,2])
ymax19 <- max(ud19$ZH@coords[,2])

xmin18 <- min(ud18$ZH@coords[,1])
xmax18 <- max(ud18$ZH@coords[,1])
ymin18 <- min(ud18$ZH@coords[,2])
ymax18 <- max(ud18$ZH@coords[,2])

```

::: {.panel-tabset .nav-pills}
##Generating KDE for 2018 data -> sieht bei uns einfach scheisse aus
```{r}
graphics::image(ud18, xlab = "x [m]", ylab = "y [m]",
                col = hcl.colors(200, palette = "heat 2", rev = TRUE))
plot(hr18_90, lty = 1, lwd = 2, border = "red", add = TRUE, axes = FALSE)
axis(1)
axis(2, pos = xmin18 - 10)
text(xmin18 - 15, ymin18 + (ymax18 - ymin18) / 2, "y [m]", 
     adj = c(NA, -4), srt = 90)
title("", line = -0.3)
```

##Generating KDE for 2018 data -> sieht bei uns einfach scheisse aus
```{r}
graphics::image(ud19, xlab = "x [m]", ylab = "y [m]",
                col = hcl.colors(200, palette = "heat 2", rev = TRUE))
plot(hr19_90, lty = 1, lwd = 2, border = "red", add = TRUE, axes = FALSE)
axis(1)
axis(2, pos = xmin19 - 10)
text(xmin19 - 15, ymin19 + (ymax19 - ymin19) / 2, "y [m]", 
     adj = c(NA, -4), srt = 90)
title("", line = -0.3)
```
:::

## Task 13
Compute the “volume of intersection” (“VI”) between the KDE surfaces (utilization distributions) of the two years. Hint: There are different ways to do that, but the adehabitatHR package has functionality for that. How do the results correspond to those of Task 9 (Jaccard Index or IoU)?

```{r}
hr18_90sf <-st_as_sf(hr18_90)
hr19_90sf <-st_as_sf(hr19_90)

## compute intersection and union
polyhr_18_19inters<- st_intersection(hr19_90sf, hr18_90sf)
polyhr_18_19union<- st_union(hr19_90sf, hr18_90sf)



```

::: {.panel-tabset .nav-pills}
##overlap of areas 
```{r}
plot(st_coordinates(hr18_90sf), xlab = "Easting [m]", ylab = "Northing [m]", 
     type = "n", asp = 1)
plot(hr18_90sf, col =alpha("cyan", 0.3), border = NA, add = TRUE)
plot(hr19_90sf, col =alpha("magenta", 0.3) , border = NA, add = TRUE)
legend("bottomleft", legend=c("KDE area 2018", "KDE area 2019"),
       fill=c("cyan", "magenta"), cex=0.8)
```

##Jaccard Index
```{r}
cat("Area of 2018:", sf::st_area(hr18_90sf), "m^2 \n",
    "Area of 2019: ", sf::st_area(hr19_90sf), "m^2 \n",
    "Intersection Area: ",sf::st_area(polyhr_18_19inters), "m^2 \n",
    "Union Area:", sf::st_area(polyhr_18_19union), "m^2 \n",
    "Jaccard Index:", sf::st_area(polyhr_18_19inters)/sf::st_area(polyhr_18_19union), "\n")
```
:::

KOMMENTAR

## Task 14
Discuss your results for this part of DC1 (density estimation). What did you find? Compare the results of this part with the clusters/polygons of Parts 1 and 2 (see note below): What are the commonalities? What are the differences? Which method(s) perform more adequately than others for the given problem and data? Which method(s) would you recommend, and which ones not? Why? (You are free to add more points to the discussion.)

KOMMENTAR

# Fourth part: Second Order Properties
## Task 15
Choose one or more distance measure functions (justify your choice) and compute it/them for

KOMMENTAR

* a. all bicycle accidents (2011 - 2021) 

::: {.panel-tabset .nav-pills}
## L-Function with envelope
```{r, echo=FALSE}
# Create a ppp object 
bike_accidents_coords <- sf::st_coordinates(bike_accidents_sf)
win <- as.owin(st_bbox(bike_accidents_sf))
bike_accidents_ppp <- spatstat.geom::ppp(x = bike_accidents_coords[,1], y =  bike_accidents_coords[,2],
                                         window = win, unitname = c("meter", "meters"))

# Generate L-function with envelope() function.
bike_accidents_enve <- spatstat.explore::envelope(bike_accidents_ppp, fun = Lest, nsim = 100, 
                                         correction = "Ripley", verbose = FALSE)
# Plot 
plot(bike_accidents_enve, main = "")
```

## MAD & DCLF Test
```{r, echo=FALSE}
# We also apply the MAD test
spatstat.explore::mad.test(bike_accidents_ppp, fun = Lest, nsim = 100, verbose = FALSE)
spatstat.explore::dclf.test(bike_accidents_ppp, fun = Lest, nsim = 100, verbose = TRUE)

```
:::

* b. bicycle accidents for one of the years selected in Task 6 

##hier haben wir ein Jahr zu viel, vorschlag 2019 raus

::: {.panel-tabset .nav-pills}
## L-Function 2018 data, with envelope
```{r, echo=FALSE}
# Create a ppp object 
bike_accidents2018_coords <- sf::st_coordinates(bike_accidents_2018_sf)
win18 <- as.owin(st_bbox(bike_accidents_2018_sf))
bike_accidents2018_ppp <- spatstat.geom::ppp(x = bike_accidents2018_coords[,1], y =  bike_accidents2018_coords[,2],
                                         window = win18, unitname = c("meter", "meters"))

# Generate L-function
bike_accidents2018_enve <- spatstat.explore::envelope(bike_accidents2018_ppp, fun = Lest, nsim = 100, 
                                         correction = "Ripley", verbose = FALSE)
# Plot 
plot(bike_accidents2018_enve, main = "")

```

## MAD & DCLF Test 2018 data
```{r, echo=FALSE}
# We also apply the MAD test
spatstat.explore::mad.test(bike_accidents2018_ppp, fun = Lest, nsim = 100, verbose = FALSE)
spatstat.explore::dclf.test(bike_accidents2018_ppp, fun = Lest, nsim = 100, verbose = TRUE)

```
:::


```{r, echo=FALSE}
## L-Function 2019 data, with envelope
# Create a ppp object 
# bike_accidents2019_coords <- sf::st_coordinates(bike_accidents_2019_sf)
# win19 <- as.owin(st_bbox(bike_accidents_2019_sf))
# bike_accidents2019_ppp <- spatstat.geom::ppp(x = bike_accidents2019_coords[,1], y =  bike_accidents2019_coords[,2],
#                                          window = win19, unitname = c("meter", "meters"))
# 
# # Generate L-function
# bike_accidents2019_enve <- spatstat.explore::envelope(bike_accidents2019_ppp, fun = Lest, nsim = 100, 
#                                          correction = "Ripley", verbose = FALSE)
# # Plot 
# plot(bike_accidents2019_enve, main = "")
```


```{r, echo=FALSE}
## MAD & DCLF Test 2019 data
# We also apply the MAD test
# spatstat.explore::mad.test(bike_accidents2019_ppp, fun = Lest, nsim = 100, verbose = FALSE)
# spatstat.explore::dclf.test(bike_accidents2019_ppp, fun = Lest, nsim = 100, verbose = TRUE)
```

* c. bicycle accidents for only the cluster points of the year selected in (b)

Restrict your analysis to the “inner city” and use the same window for all point sets. It’s up to you to define the extent of the “inner city” and explain/justify what that means in terms of this data challenge.


```{r}
#Intersection
districts1<-districts[12,]

dist1_2018<-st_intersection(filter(bike_accidents, AccidentYear ==2018),districts1)
# 
# ggplot()+
#   geom_sf(data=boundary, aes(color="white"))+
#   geom_sf(data=dist1_2018, aes(color="black"))+
#   theme(legend.position="none")#looks good

```


```{r, echo=FALSE}
## Choosing a subset of districts
# ggplot(districts)+
#   geom_sf(aes(fill=KNR))+
#   geom_sf_label(aes(label = KNAME))+
#   theme_minimal() +
#   coord_sf(datum = NA)+
#   xlab("")+
#   ylab("")
```

::: {.panel-tabset .nav-pills}

## L-Function 2018 data, with envelope for district 1
```{r, echo=FALSE}
# Create a ppp object 

bike_accidents2018_coords1 <- sf::st_coordinates(dist1_2018)
win18_1 <- as.owin(st_bbox(dist1_2018))
bike_accidents2018_ppp_1 <- spatstat.geom::ppp(x = bike_accidents2018_coords1[,1], y =  bike_accidents2018_coords1[,2],
                        window = win18_1, unitname = c("meter", "meters"))

# Generate L-function
bike_accidents2018_enve1 <- spatstat.explore::envelope(bike_accidents2018_ppp_1, fun = Lest, nsim = 100, correction = "Ripley", verbose = FALSE)
# Plot 
plot(bike_accidents2018_enve1, main = "")

```

## MAD & DCLF Test 2018 data
```{r, echo=FALSE}
# We also apply the MAD test
spatstat.explore::mad.test(bike_accidents2018_ppp_1, fun = Lest, nsim = 100, verbose = FALSE)
spatstat.explore::dclf.test(bike_accidents2018_ppp_1, fun = Lest, nsim = 100, verbose = TRUE)

```
:::
KOMMENTAR

## Task 16
Now choose the following two pairs of years, 2018 & 2019, as well as 2018 & 2021, and compute the cross-X function, where “X” stands for the function(s) you used in Task 15. Use the AccidentYear as the marks to produce a marked point pattern.

::: {.panel-tabset .nav-pills}

## marked point pattern
```{r, echo=FALSE}
# reate a marked ppp object
marks_bike_accidents_ppp <- spatstat.geom::setmarks(bike_accidents_ppp, factor(bike_accidents_sf$AccidentYear))

bike_accidents181921 <- bike_accidents_sf|> 
  filter(bike_accidents_sf$AccidentYear %in% c("2018", "2019", "2021"))

# Summary will show frequency table per Year
# summary(bike_accidents181921)

ggplot() +
  geom_sf(data = bike_accidents181921, aes(colour = AccidentYear))  +
  geom_sf(data = districts, color = "black", fill = NA) +
  coord_sf(datum = NA)+
  theme_minimal()+
  guides(fill=guide_legend(title="Accident year"))
  
```

## Cross-L-function of bike accidents 2018 vs. 2019
```{r, echo=FALSE}
acc_2018_2019_clf_env <- spatstat.explore::envelope(marks_bike_accidents_ppp, fun = Lcross, 
                                                    i = "2018", j = "2019", nsim = 100, 
                                                    correction = "Ripley", verbose = FALSE)

# Plot it
plot(acc_2018_2019_clf_env, main = "")
```

## Cross-L-function of bike accidents 2018 vs. 2021
```{r, echo=FALSE}
#create ppp for 2021 data
bike_accidents_2021_sf <- bike_accidents_sf |> 
  filter(bike_accidents_sf$AccidentYear == 2021)

# drop everything except geometry
bike_accidents_2021_sf <- st_zm(bike_accidents_2021_sf[,22])

bike_accidents2021_coords <- sf::st_coordinates(bike_accidents_2021_sf)
win21 <- as.owin(st_bbox(bike_accidents_2021_sf))
bike_accidents2021_ppp <- spatstat.geom::ppp(x = bike_accidents2021_coords[,1], y =  bike_accidents2021_coords[,2],
                                         window = win21, unitname = c("meter", "meters"))


acc_2018_2021_clf_env <- spatstat.explore::envelope(marks_bike_accidents_ppp, fun = Lcross, 
                                                    i = "2018", j = "2021", nsim = 100, 
                                                    correction = "Ripley", verbose = FALSE)

# Plot it
plot(acc_2018_2021_clf_env, main = "")
```
:::

## Task 17
Discuss your results. Similarities and differences between the various point sets? Noteworthy spatial and/or temporal patterns? Is any difference observable in the patterns of the cross-X function in the transition to the Covid-19 pandemic? etc. etc. Note: Consider in your interpretation that the distance scale may change between years.

KOMMENTAR 

## Task 18
From the bicycle accidents data, choose at least two relevant variables that make sense being compared, e.g. two different accident types, severity levels, times of day, years etc. For these selected accidents, compute the counts within the ‘statistical zones’ of Zurich and use these counts to compute the Getis-Ord G*-statistic for each of your counts layers. Visualize your results appropriately.

```{r}
# read data of statistical zones
zh_stat_zone <- read.csv("Session_5/data/stzh.adm_statzonen_v.csv")
zh_stat_zone_sf <- st_as_sf(zh_stat_zone,wkt = "geometry", crs = 2056)
zh_stat_zone_sf <- zh_stat_zone_sf[, c(1,2,3,9)]


nn_dis <- 1500

getisbikedata_df <- filter(accidents_no_geom,AccidentInvolvingBicycle == "true") 
getisbikedata_df<-getisbikedata_df[,c(11,20,21,24)]

# Calculate centroid
zh_stat_zone_zentro <- st_centroid(zh_stat_zone_sf)


### Create proportions for accident types
getisbikedata_df$lightinj <- with(getisbikedata_df, ifelse(AccidentSeverityCategory_en=="Accident with light injuries", 1.0, 0.0))

getisbikedata_df$severinj <- with(getisbikedata_df, ifelse(AccidentSeverityCategory_en=="Accident with severe injuries", 1.0, 0.0))

getisbikedata_df$propdam <- with(getisbikedata_df, ifelse(AccidentSeverityCategory_en=="Accident with property damage", 1.0, 0.0))

getisbikedata_df$fatal <- with(getisbikedata_df, ifelse(AccidentSeverityCategory_en=="Accident with fatalities", 1.0, 0.0))


getisbikedata_sf<-st_as_sf(getisbikedata_df,coords = c("AccidentLocation_CHLV95_E",  "AccidentLocation_CHLV95_N"), crs=2056)

getisbikedata_sf_join <- st_join(x = getisbikedata_sf, y = zh_stat_zone_sf, left = FALSE)

smry <- getisbikedata_sf_join |> 
  group_by(stzname) |> 
  summarise(sum_lightinj = sum(lightinj),
            sum_severinj = sum(severinj),
            sum_propdam = sum(propdam),
            sum_fatal = sum(fatal))
smry_df <- st_drop_geometry(smry)

acc_per_zentro <- full_join(zh_stat_zone_zentro, smry_df, by = "stzname")


acc_per_zentro <- acc_per_zentro  |> 
  rowwise() |> 
  mutate(sum_acc = sum(sum_lightinj,sum_severinj, sum_fatal, sum_propdam, na.rm = T))


acc_per_zentro <- filter(acc_per_zentro, sum_acc > 0)


acc_per_zentro <- acc_per_zentro  |> 
  mutate(per_lightinj = 1/sum_acc*sum_lightinj,
         per_severinj = 1/sum_acc*sum_severinj,
         per_fatal = 1/sum_acc*sum_fatal,
         per_propdam = 1/sum_acc*sum_propdam)


acc_per_zentro_df <- extract(acc_per_zentro, geometry, into = c('Lat', 'Lon'), '\\((.*),(.*)\\)', conv = T)
acc_per_zentro_sf <- acc_per_zentro


# create list of euclidean neighbors with min. distance = 0 and max. distance = nn_dis 
bike_acc_nb <- spdep::dnearneigh(acc_per_zentro_sf, 0, nn_dis) # kann auch warnmeldungen generieren Warnmeldung:In spdep::dnearneigh(getisbikedata_sf, 0, nn_dis) : neighbour object has 3 sub-graphs

# convert into list with spatial weights, B = binary weight
bike_acc_lw <- spdep::nb2listw(spdep::include.self(bike_acc_nb), style = "B")

# Create the line links from the nb object, requesting an sf object to be returned.
# CRS needs to be set as it was carried over to the nb object.
bike_acc_links <- 
   spdep::nb2lines(bike_acc_nb, coords = sf::st_geometry(acc_per_zentro_sf), as_sf = TRUE) |>
   sf::st_set_crs(2056)#####hier haben sie keine warnmeldungIn spdep::dnearneigh(getisbikedata_sf, 0, nn_dis) : neighbour object has 33 sub-graphs
# 
# # Plot the neighbor links using functions from the tmap package
tmap::tm_shape(districts) + 
  tmap::tm_borders(col = "gray") +
  tmap::tm_shape(bike_acc_links) + 
  tmap::tm_lines(col = "red", lwd = 0.5) +
  tmap::tm_shape(acc_per_zentro) +
  tmap::tm_dots(col = "black", size = 0.1) +
  tmap::tm_scale_bar(position = c("right", "bottom"), width = 0.2)
```

::: {.panel-tabset .nav-pills}

### Gi*-statistic for light injuries
```{r}
sads_lG_light <-
    spdep::localG(x = as.numeric(unlist(acc_per_zentro_df[, 11])), listw = bike_acc_lw)

s_lG_light <- sads_lG_light[1:length(sads_lG_light)]   # convert to vector
tmp_sf_light <- bind_cols(acc_per_zentro_sf, as.data.frame(s_lG_light))


tmap::tm_shape(zh_stat_zone_sf) +
    tmap::tm_borders(col = "gray") +
    tmap::tm_shape(tmp_sf_light) +
    tmap::tm_dots(
      size = 0.2,
      col = "s_lG_light",
      n = 6,
      midpoint = 0,
      palette = "-RdYlBu",
      title.size = 0.2,
      title = paste("Deviation")
    ) +
    tmap::tm_layout(
      main.title.size = 1.0,
      main.title.fontface = "bold",
      main.title.position = c("left", "top"),
      legend.position = c("left", "top"),
      frame = FALSE,
      inner.margins = c(0.05, 0.05, 0.05, 0.05)
    ) +
    tmap::tm_scale_bar(position = c("right", "bottom"), width = 0.2)
```

### Gi*-statistic for severe injuries
```{r}
sads_lG_severe <-
    spdep::localG(x = as.numeric(unlist(acc_per_zentro_df[, 12])), listw = bike_acc_lw)

s_lG_severe <- sads_lG_severe[1:length(sads_lG_severe)]   # convert to vector
tmp_sf_severe <- bind_cols(acc_per_zentro_sf, as.data.frame(s_lG_severe))


tmap::tm_shape(zh_stat_zone_sf) +
    tmap::tm_borders(col = "gray") +
    tmap::tm_shape(tmp_sf_severe) +
    tmap::tm_dots(
      size = 0.2,
      col = "s_lG_severe",
      n = 6,
      midpoint = 0,
      palette = "-RdYlBu",
      title.size = 0.2,
      title = paste("Deviation")
    ) +
    tmap::tm_layout(
      main.title.size = 1.0,
      main.title.fontface = "bold",
      main.title.position = c("left", "top"),
      legend.position = c("left", "top"),
      frame = FALSE,
      inner.margins = c(0.05, 0.05, 0.05, 0.05)
    ) +
    tmap::tm_scale_bar(position = c("right", "bottom"), width = 0.2)

```

### Gi*-statistic for fatal injuries
```{r}
sads_lG_fatal <-
    spdep::localG(x = as.numeric(unlist(acc_per_zentro_df[, 13])), listw = bike_acc_lw)

s_lG_fatal <- sads_lG_fatal[1:length(sads_lG_fatal)]   # convert to vector
tmp_sf_fatal <- bind_cols(acc_per_zentro_sf, as.data.frame(s_lG_fatal))


# tmap::tm_shape(zh_stat_zone_sf) +
#     tmap::tm_borders(col = "gray") +
#     tmap::tm_shape(tmp_sf_fatal) +
#     tmap::tm_dots(
#       size = 0.2,
#       col = "s_lG_fatal",
#       n = 6,
#       midpoint = 0,
#       palette = "-RdYlBu",
#       title.size = 0.2,
#       title = paste("Deviation")
#     ) +
#     tmap::tm_layout(
#       main.title.size = 1.0,
#       main.title.fontface = "bold",
#       main.title.position = c("left", "top"),
#       legend.position = c("left", "top"),
#       frame = FALSE,
#       inner.margins = c(0.05, 0.05, 0.05, 0.05)
#     ) +
#     tmap::tm_scale_bar(position = c("right", "bottom"), width = 0.2)

```


### Gi*-statistic for property damage
```{r}
sads_lG_propdam <-
    spdep::localG(x = as.numeric(unlist(acc_per_zentro_df[, 14])), listw = bike_acc_lw)

s_lG_propdam <- sads_lG_propdam[1:length(sads_lG_propdam)]   # convert to vector
tmp_sf_propdam <- bind_cols(acc_per_zentro_sf, as.data.frame(s_lG_propdam))


tmap::tm_shape(zh_stat_zone_sf) +
    tmap::tm_borders(col = "gray") +
    tmap::tm_shape(tmp_sf_propdam) +
    tmap::tm_dots(
      size = 0.2,
      col = "s_lG_propdam",
      n = 6,
      midpoint = 0,
      palette = "-RdYlBu",
      title.size = 0.2,
      title = paste("Deviation")
    ) +
    tmap::tm_layout(
      main.title.size = 1.0,
      main.title.fontface = "bold",
      main.title.position = c("left", "top"),
      legend.position = c("left", "top"),
      frame = FALSE,
      inner.margins = c(0.05, 0.05, 0.05, 0.05)
    ) +
    tmap::tm_scale_bar(position = c("right", "bottom"), width = 0.2)
```
:::


## Task 19
Discuss your results. What did you find regarding the hot and cold spots in your accident count layers? How do they compare to each other across layers and across (past) methods? etc. Discuss also the influence of the parameter settings (e.g., neighbor search distance, spatial weight formation) on your results.


KOMMENTAR

# Timesheet
Each person has invested about 25 hours into this project.
