---
title: "Data Challenge 1"
author: "Saskia Gianola / Sarah Wirth"
date: "October/November 2024"
format: 
  html:
    embed-resources: true
    fig_caption: true
    fig-align: center
    highlight: tango
    number-sections: false
    theme: journal
    toc: true
    toc_depth: 2
    toc_float: true
execute:                      # Set global options for execution of code blocks
  echo: false
  warning: false
  message: false
---
# Introduction
This file includes the assignments, code and interpretation of Data Challenge 1. The code was elaborated as collaboration between Sarah Wirth and Saskia Gianola. For this work no language models like ChatGPT have been used.

## Packages
```{r}
library(dplyr)
library(ggplot2)
library(lubridate)
library(sf)
library(cluster)
library(dbscan)
library(fpc)
library(concaveman)
library(adehabitatHR)
library(spatstat)
library(spdep)
library(ks)

```

# First part: Spatial Clustering
## Task 1
Download and import the road accident data from Open Data Zurich (ODZ) using an appropriate file format. If needed, transform to the Swiss projected CH1903+/LV95 coordinate system (EPSG = 2056).

```{r, echo=TRUE, , results='hide'}
accidents <- st_read("Session2/roadtrafficaccidentlocations.gpkg")
boundary <-st_read("Session2/Zurich_city_boundary_2024.gpkg")
districts <-st_read("Session2/Zurich_city_districts_2024.gpkg")
```
As all three layers are already in the Swiss projected CH1903+/LV95, there is no need for transformation. 

## Task 2
Report the following numbers in table(s):
  
```{r}
accidents_no_geom <- st_drop_geometry(accidents) # drop geometry to make code more efficient

acc_sever <- accidents_no_geom |> 
   count(AccidentSeverityCategory_en)

acc_type <- accidents_no_geom |> 
  count(AccidentType_en)

acc_ped <- accidents_no_geom |> 
  count(AccidentInvolvingPedestrian)

acc_bike <- accidents_no_geom |> 
  count(AccidentInvolvingBicycle)

acc_moto <- accidents_no_geom |> 
  count(AccidentInvolvingMotorcycle)

acc_ped_moto <- accidents_no_geom |> 
  count(AccidentInvolvingPedestrian, AccidentInvolvingMotorcycle)

acc_ped_bike <- accidents_no_geom |> 
  count(AccidentInvolvingPedestrian, AccidentInvolvingBicycle)

acc_moto_bike <- accidents_no_geom |> 
  count(AccidentInvolvingMotorcycle, AccidentInvolvingBicycle)

acc_ped_bike_moto <- accidents_no_geom |> 
  count(AccidentInvolvingPedestrian, AccidentInvolvingBicycle, AccidentInvolvingMotorcycle)
  
```
* a. Number of accidents by accident severity category
  
```{r}
acc_sever
```
  
* b. Number of accidents by accident type
  
```{r}
acc_type
```

  
* c. Number of accidents involving pedestrians, bicycles, and motorcycles, respectively. And combinations thereof (pedestrian AND bicycle, pedestrian AND motorcycle etc.). Are there any accidents involving all three modes (pedestrian, bicycle, motorcycle)?
  
```{r}
acc_ped
acc_bike
acc_moto
acc_ped_bike
acc_ped_moto
acc_moto_bike
acc_ped_bike_moto
```

## Task 3
Generate a plot showing the temporal evolution of the number of accidents from 2011 to 2023. Label each year with the corresponding number of accidents. Choose a plot type that is suitable for this type of temporal data. Bonus: Show also the data for the bicycle accidents (cf. Task 4) in the same plot.

```{r, echo=FALSE}
numyearbi <- accidents |> group_by(AccidentYear, AccidentInvolvingBicycle) |>
  summarise(n=n())
numyear <- numyearbi |> group_by(AccidentYear)  |> 
  summarise(n=n())
  

ggplot(numyearbi, aes(x=AccidentYear, y=n,fill=AccidentInvolvingBicycle, label=n)) +
  geom_bar(position="stack", stat="identity")+
  geom_text(size = 3, position = position_stack(vjust = 0.5)) +
  ylab("Total number of accidents") +
  xlab("Year") +
  theme_bw()+
  guides(fill=guide_legend(title="Accident involves bicycles"))

```

## Task 4
Select only those accidents that involved a bicycle. **From now on, and for the remainder of DC1, we will restrict our analysis to the accidents involving bicycles.** With this subset, produce a map showing the bicycle accident data colored by accident severity category. Use a basemap such as OpenStreetMap and/or the boundary data available on OLAT, so the accidents can be visually and spatially referenced.

::: {.panel-tabset .nav-pills}
# All bike accidents
```{r, echo=FALSE}
bike_accidents <- accidents |> 
  filter(AccidentInvolvingBicycle == "true")


#Version normal
ggplot() +
  geom_sf(data = bike_accidents, mapping = aes(color = AccidentSeverityCategory)) +
  geom_sf(data = districts, color = "black", fill = NA) +
  coord_sf(datum = NA)+
  theme(legend.position = "bottom", panel.grid.major = element_line(colour = "transparent")) +
  theme_minimal()+
  scale_color_manual(values = c("red","orange2",  "gold", "blue"),
                               name = "Accident Severity",
                               breaks = c("as1",  "as3","as2", "as4"),
                               labels = c("fatalities", 
                                          "severe injuries",
                                          "light injuries",
                                          "property damage"))
#Version mit alpha
# ggplot() +
#   geom_sf(data = bike_accidents, mapping = aes(color =AccidentSeverityCategory)) +
#   geom_sf(data = districts, color = "black", fill = NA, ) +
#   coord_sf(datum = NA)+
#   theme(legend.position = "bottom", panel.grid.major = element_line(colour = "transparent")) +
#   theme_minimal()+
#   scale_color_manual(values = c(alpha("red",alpha = 1.0), alpha("orange2",alpha = 0.8), alpha("gold",alpha = 0.8), alpha("blue",alpha = 0.8)),
#                                name = "Accident Severity",
#                                breaks = c("as1",  "as3","as2", "as4"),
#                                labels = c("fatalities", 
#                                           "severe injuries",
#                                           "light injuries",
#                                           "property damage"))
# 
# #Version mit small multiples
# ggplot() +
#   geom_sf(data = bike_accidents, mapping = aes(color = AccidentSeverityCategory)) +
#   geom_sf(data = districts, color = "black", fill = NA) +
#   facet_wrap(~AccidentSeverityCategory)+
#   coord_sf(datum = NA)+
#   theme(legend.position = "bottom", panel.grid.major = element_line(colour = "transparent")) +
#   theme_minimal()+
#   theme(strip.text = element_blank())+
#   scale_color_manual(values = c("red","orange2",  "gold", "blue"),
#                                name = "Accident Severity",
#                                breaks = c("as1",  "as3","as2", "as4"),
#                                labels = c("fatalities", 
#                                           "severe injuries",
#                                           "light injuries",
#                                           "property damage"))
```
# bike accidents with fatalities
```{r}
bike_accidents_fatal <- bike_accidents |> 
  filter(AccidentSeverityCategory == "as1")

ggplot() +
  geom_sf(data = bike_accidents_fatal, color = "red") +
  geom_sf(data = districts, color = "black", fill = NA, ) +
  coord_sf(datum = NA)+
  theme_minimal()
```
# bike accidents with severe injuries
```{r}
bike_accidents_severe <- bike_accidents |> 
  filter(AccidentSeverityCategory == "as2")

ggplot() +
  geom_sf(data = bike_accidents_severe, color = "orange2") +
  geom_sf(data = districts, color = "black", fill = NA, ) +
  coord_sf(datum = NA)+
  theme_minimal()
```
# bike accidents with light injuries
```{r}
bike_accidents_light <- bike_accidents |> 
  filter(AccidentSeverityCategory == "as3")

ggplot() +
  geom_sf(data = bike_accidents_light, color = "gold") +
  geom_sf(data = districts, color = "black", fill = NA, ) +
  coord_sf(datum = NA)+
  theme_minimal()
```
# bike accidents with property damage
```{r}
bike_accidents_damage <- bike_accidents |> 
  filter(AccidentSeverityCategory == "as4")

ggplot() +
  geom_sf(data = bike_accidents_damage, color = "blue") +
  geom_sf(data = districts, color = "black", fill = NA, ) +
  coord_sf(datum = NA)+
  theme_minimal()
```
::: 

## Task 5 
Imagine you are given the task of detecting spatial clusters of elevated bicycle accident occurrence (without considering their severity). How would you characterize such "bicycle accident clusters"? Try to define properties that can be used to describe and identify such clusters, and that can be used to choose and parameterize a clustering method suitable for the task. Try to use natural, but precise and concise language in your answer.

KOMMENTAR


## Task 6
From the bicycle accidents, extract the years 2018 to 2021 and compute clusters for each year separately, using a clustering method you deem appropriate for the task, and choose the control parameters appropriately to capture the types of clusters you had in mind in your definition of Task 5. Justify your choice.

```{r, echo=FALSE}
bike_accidents2018 <- st_coordinates(bike_accidents |> 
  filter(AccidentYear == "2018"))
bike_accidents2019 <- st_coordinates(bike_accidents |> 
  filter(AccidentYear == "2019"))
bike_accidents2020 <- st_coordinates(bike_accidents |> 
  filter(AccidentYear == "2020"))
bike_accidents2021 <- st_coordinates(bike_accidents |> 
  filter(AccidentYear == "2021"))
```

::: {.panel-tabset .nav-pills}
## Reachability Plot 2018 data
```{r, echo=FALSE}
# clustering with optics
ops_reach2018 <- optics(bike_accidents2018)
ops_reach2018 <- extractDBSCAN(ops_reach2018, eps_cl = 500)
ops_reach2018
plot(ops_reach2018)
```

## clustered points 2018 data
```{r, echo=FALSE}
plot(bike_accidents2018, cex = 0.4, pch = 19, col = ops_reach2018$cluster + 1, asp = 1)
```

## Convex Cluster Hulls 2018 data
```{r, echo=FALSE}
hullplot(bike_accidents2018, ops_reach2018, asp = 1)
```

## Reachability Plot 2019 data
```{r, echo=FALSE}
# clustering with optics
ops_reach2019 <- optics(bike_accidents2019)
ops_reach2019 <- extractDBSCAN(ops_reach2019, eps_cl = 500)
ops_reach2019
plot(ops_reach2019)
```

## clustered points 2019 data
```{r, echo=FALSE}
plot(bike_accidents2019, cex = 0.4, pch = 19, col = ops_reach2019$cluster + 1, asp = 1)
```

## Convex Cluster Hulls 2019 data
```{r, echo=FALSE}
hullplot(bike_accidents2019, ops_reach2019, asp = 1)
```
:::

## Task 7
Discuss your results, including also limitations or problems, and possible other methods that you could have used.

KOMMENTAR 

# Second part: Polygon Delineation
## Task 8
Given the clusters that you have extracted in Part 1 of the DC1 assignment:

* a. Define a set of criteria that a method should fulfill that can be used to delineate the given clusters by polygons. Use free text for these definitions, but try to be concise and precise. (Note: These criteria can also be used in the subsequent Discussion to evaluate whether they have been met.)

KOMMENTAR

* b. Choose a polygon delineation method that you deem appropriate in light of the above
criteria. Justify your choice.

KOMMENTAR

## Task 9
From the years 2018 to 2021 for which you computed clusters in Task 6, choose at least two years and apply your polygon delineation method of choice to each of these two years separately. Compute the Jaccard Index (aka Intersection over Union) for pair(s) of selected years and present and discuss the results.

##da stimmt noch immer was mit dieser Intersection nicht

```{r , echo = FALSE}
# add cluster info to data
bike_acc2018_clus <- st_as_sf(as.data.frame(cbind(bike_accidents2018, ops_reach2018$cluster)), 
                              coords = c("X", "Y"), crs = 2056)
bike_acc2019_clus <- st_as_sf(as.data.frame(cbind(bike_accidents2019, ops_reach2019$cluster)), 
                              coords = c("X", "Y"), crs = 2056)

summary(bike_acc2018_clus) # for 2018 data, there are 4 clusters
summary(bike_acc2019_clus) # for 2019 data, there are 7 clusters

# separate data into single clusters

bike_acc2018_c1 <- bike_acc2018_clus |> 
  filter(V4 == 1)
bike_acc2018_c2 <- bike_acc2018_clus |> 
  filter(V4 == 2)
bike_acc2018_c3 <- bike_acc2018_clus |> 
  filter(V4 == 3)
bike_acc2018_c4 <- bike_acc2018_clus |> 
  filter(V4 == 4)
# bike_acc2018_c5 <- bike_acc2018_clus |> 
#   filter(V4 == 5)
# bike_acc2018_c6 <- bike_acc2018_clus |> 
#   filter(V4 == 6)
# bike_acc2018_c7 <- bike_acc2018_clus |> 
#   filter(V4 == 7)
# bike_acc2018_c8 <- bike_acc2018_clus |> 
#   filter(V4 == 8)

bike_acc2019_c1 <- bike_acc2019_clus |> 
  filter(V4 == 1)
bike_acc2019_c2 <- bike_acc2019_clus |> 
  filter(V4 == 2)
bike_acc2019_c3 <- bike_acc2019_clus |> 
  filter(V4 == 3)
bike_acc2019_c4 <- bike_acc2019_clus |> 
  filter(V4 == 4)
bike_acc2019_c5 <- bike_acc2019_clus |> 
  filter(V4 == 5)
bike_acc2019_c6 <- bike_acc2019_clus |> 
  filter(V4 == 6)
bike_acc2019_c7 <- bike_acc2019_clus |> 
  filter(V4 == 7)
# bike_acc2019_c8 <- bike_acc2019_clus |> 
#   filter(V4 == 8)
# bike_acc2019_c9 <- bike_acc2019_clus |> 
#   filter(V4 == 9)
# bike_acc2019_c10 <- bike_acc2019_clus |> 
#   filter(V4 == 10)

# compare thresholds
cave_acc2018_2 <- concaveman(bike_acc2018_c1, concavity = 2, length_threshold = 0)
cave_acc2018_1 <- concaveman(bike_acc2018_c1, concavity = 1, length_threshold = 0)
cave_acc2018_05 <- concaveman(bike_acc2018_c1, concavity = 0.5, length_threshold = 0)
```
::: {.panel-tabset .nav-pills}
# find best concavity value
```{r}
ggplot() +
  geom_sf(data = districts, color = "black", fill = NA) +
  geom_sf(data=bike_acc2018_c1, size = 0.5) +
  geom_sf(data = cave_acc2018_2, color = "cyan", fill = alpha("cyan", alpha=0.2)) +
  geom_sf(data = cave_acc2018_1, color = "magenta", fill = alpha("magenta", alpha=0.2)) +
  geom_sf(data = cave_acc2018_05, color = "yellow", fill = alpha("yellow", alpha=0.2)) +
  coord_sf(datum = NA)+
  ggtitle("find best concavity value")+
  theme_minimal()

# 1 seems best value for concavity
bike_acc2018_c1_con <- concaveman(bike_acc2018_c1, concavity = 1, length_threshold = 0)
bike_acc2018_c2_con <- concaveman(bike_acc2018_c2, concavity = 1, length_threshold = 0)
bike_acc2018_c3_con <- concaveman(bike_acc2018_c3, concavity = 1, length_threshold = 0)
bike_acc2018_c4_con <- concaveman(bike_acc2018_c4, concavity = 1, length_threshold = 0)
# bike_acc2018_c5_con <- concaveman(bike_acc2018_c5, concavity = 1, length_threshold = 0)
# bike_acc2018_c6_con <- concaveman(bike_acc2018_c6, concavity = 1, length_threshold = 0)
# bike_acc2018_c7_con <- concaveman(bike_acc2018_c7, concavity = 1, length_threshold = 0)
# bike_acc2018_c8_con <- concaveman(bike_acc2018_c8, concavity = 1, length_threshold = 0)

bike_acc2019_c1_con <- concaveman(bike_acc2019_c1, concavity = 1, length_threshold = 0)
bike_acc2019_c2_con <- concaveman(bike_acc2019_c2, concavity = 1, length_threshold = 0)
bike_acc2019_c3_con <- concaveman(bike_acc2019_c3, concavity = 1, length_threshold = 0)
bike_acc2019_c4_con <- concaveman(bike_acc2019_c4, concavity = 1, length_threshold = 0)
bike_acc2019_c5_con <- concaveman(bike_acc2019_c5, concavity = 1, length_threshold = 0)
bike_acc2019_c6_con <- concaveman(bike_acc2019_c6, concavity = 1, length_threshold = 0)
bike_acc2019_c7_con <- concaveman(bike_acc2019_c7, concavity = 1, length_threshold = 0)
# bike_acc2019_c8_con <- concaveman(bike_acc2019_c8, concavity = 1, length_threshold = 0)
# bike_acc2019_c9_con <- concaveman(bike_acc2019_c9, concavity = 1, length_threshold = 0)
# bike_acc2019_c10_con <- concaveman(bike_acc2019_c10, concavity = 1, length_threshold = 0)
```

# Clusters of bike accidents 2018
```{r}
ggplot() +
  geom_sf(data = districts, color = "black", fill = NA) +
  geom_sf(data = bike_acc2018_c1, color = "black", size = 0.5) +
  geom_sf(data = bike_acc2018_c1_con, color = "pink", fill = alpha("pink", alpha=0.3)) + 
  geom_sf(data = bike_acc2018_c2, color = "black", size = 0.5) +
  geom_sf(data = bike_acc2018_c2_con, color = "purple", fill = alpha("purple", alpha=0.3)) + 
  geom_sf(data = bike_acc2018_c3, color = "black", size = 0.5) +
  geom_sf(data = bike_acc2018_c3_con, color = "seagreen", fill = alpha("seagreen", alpha=0.3)) + 
  geom_sf(data = bike_acc2018_c4, color = "black", size = 0.5) +
  geom_sf(data = bike_acc2018_c4_con, color = "chartreuse", fill = alpha("chartreuse", alpha=0.3)) + 
  # geom_sf(data = bike_acc2018_c5, color = "black", size = 0.5) +
  # geom_sf(data = bike_acc2018_c5_con, color = "blue", fill = alpha("blue", alpha=0.3)) + 
  # geom_sf(data = bike_acc2018_c6, color = "black", size = 0.5) +
  # geom_sf(data = bike_acc2018_c6_con, color = "lightblue", fill = alpha("lightblue", alpha=0.3)) + 
  # geom_sf(data = bike_acc2018_c7, color = "black", size = 0.5) +
  # geom_sf(data = bike_acc2018_c7_con, color = "orange", fill = alpha("orange", alpha=0.3)) + 
  # geom_sf(data = bike_acc2018_c8, color = "black", size = 0.5) +
  # geom_sf(data = bike_acc2018_c8_con, color = "red", fill = alpha("red", alpha=0.3)) +
  theme_minimal() +
  coord_sf(datum = NA)
```

# Clusters of bike accidents 2019
```{r}
ggplot() +
  geom_sf(data = districts, color = "black", fill = NA) +
  geom_sf(data = bike_acc2019_c1, color = "black", size = 0.5) +
  geom_sf(data = bike_acc2019_c1_con, color = "pink", fill = alpha("pink", alpha=0.3)) + 
  geom_sf(data = bike_acc2019_c2, color = "black", size = 0.5) +
  geom_sf(data = bike_acc2019_c2_con, color = "purple", fill = alpha("purple", alpha=0.3)) + 
  geom_sf(data = bike_acc2019_c3, color = "black", size = 0.5) +
  geom_sf(data = bike_acc2019_c3_con, color = "seagreen",  fill = alpha("seagreen", alpha=0.3)) + 
  geom_sf(data = bike_acc2019_c4, color = "black", size = 0.5) +
  geom_sf(data = bike_acc2019_c4_con, color = "chartreuse",fill = alpha("chartreuse", alpha=0.3)) + 
  geom_sf(data = bike_acc2019_c5, color = "black", size = 0.5) +
  geom_sf(data = bike_acc2019_c5_con, color = "blue", fill = alpha("blue", alpha=0.3)) + 
  geom_sf(data = bike_acc2019_c6, color = "black", size = 0.5) +
  geom_sf(data = bike_acc2019_c6_con, color = "lightblue",  fill = alpha("lightblue", alpha=0.3)) + 
  geom_sf(data = bike_acc2019_c7, color = "black", size = 0.5) +
  geom_sf(data = bike_acc2019_c7_con, color = "orange", fill = alpha("orange", alpha=0.3))  + 
  # geom_sf(data = bike_acc2019_c8, color = "black", size = 0.5) +
  # geom_sf(data = bike_acc2019_c8_con, color = "red",  fill = alpha("red", alpha=0.3)) +
  # geom_sf(data = bike_acc2019_c9, color = "black", size = 0.5) +
  # geom_sf(data = bike_acc2019_c9_con, color = "gold",  fill = alpha("gold", alpha=0.3)) + 
  # geom_sf(data = bike_acc2019_c10, color = "black", size = 0.5) +
  # geom_sf(data = bike_acc2019_c10_con, color = "magenta",  fill = alpha("magenta", alpha=0.3))+
  theme_minimal() +
  coord_sf(datum = NA)
```

# Jaccard Index
```{r}
# Compute the Jaccard Index
## unify single polygones from 2018 and 2019
poly2018 <- st_union(bike_acc2018_c1_con, 
                     bike_acc2018_c2_con,
                     bike_acc2018_c3_con,
                     bike_acc2018_c4_con,
                     # bike_acc2018_c5_con,
                     # bike_acc2018_c6_con,
                     # bike_acc2018_c7_con,
                     # bike_acc2018_c8_con
                     )
poly2019 <- st_union(bike_acc2019_c1_con, 
                     bike_acc2019_c2_con,
                     bike_acc2019_c3_con,
                     bike_acc2019_c4_con,
                     bike_acc2019_c5_con,
                     bike_acc2019_c6_con,
                     bike_acc2019_c7_con,
                     # bike_acc2019_c8_con,
                     # bike_acc2019_c9_con,
                     # bike_acc2019_c10_con
                     )

## compute difference
poly2018_2019_diff <- st_difference(poly2018, poly2019)
poly2019_2018_diff <- st_difference(poly2019, poly2018)
poly_18_19diff <- st_union(poly2018_2019_diff, poly2019_2018_diff)

plot(st_coordinates(poly2018), xlab = "Easting [m]", ylab = "Northing [m]", 
     type = "n", asp = 1)
plot(poly2018, col =alpha("cyan", 0.3), border = NA, add = TRUE)
plot(poly2019, col =alpha("magenta", 0.3) , border = NA, add = TRUE)
plot(poly_18_19diff, border = "purple", add = TRUE)

cat("Area of 2018:", sf::st_area(poly2018), "m^2 \n",
    "Area of 2019: ", sf::st_area(poly2019), "m^2 \n",
    "Difference Area:    ", sf::st_area(poly_18_19diff), "m^2 \n")
```
:::

KOMMENTAR

## Task 10
Overall, what did you find with the above steps? What do these steps tell you about the situation of bicycle accidents in Zurich? How useful are the methods used so far in analysing the given data? Any other points of note?

KOMMENTAR

# Third part: Density estimation
## Task 11
Similarly to the clustering and polygon delineation tasks carried out in Parts 1 and 2 of DC1, respectively, start off by defining criteria for using KDE to detect areas/hotspots of elevated bicycle accident density, and explain your reasoning.

KOMMENTAR

## Task 12
Choose any two years from the years 2018 to 2021 (justify your choice of years) and compute the KDE surfaces for each of these two separately and visualize your results. You are free to choose the KDE implementation (i.e., R package and function(s)) as well as the parameters (bandwidth selection method, etc.), but you should document your choices and discuss, in the subsequent Task 14, your results in light of your choices.

KOMMENTAR 

```{r}
# get sf data for bike accidents in 2018 and 2019
bike_accidents_sf <- bike_accidents|> 
  filter(bike_accidents$AccidentInvolvingBicycle == "true")

bike_accidents_2018_sf <- bike_accidents_sf |> 
  filter(bike_accidents_sf$AccidentYear == 2018)
bike_accidents_2019_sf <- bike_accidents_sf |> 
  filter(bike_accidents_sf$AccidentYear == 2019)

# drop everything except geometry
bike_accidents_2018_og <- st_zm(bike_accidents_2018_sf[,22])
bike_accidents_2019_og <- st_zm(bike_accidents_2019_sf[,22])

# convert to SpatialPointsDataFrame
bike_acc2018_point <- as(bike_accidents_2018_og, "Spatial")
bike_acc2019_point <- as(bike_accidents_2019_og, "Spatial")

# get coordinates and drop Z
bike_acc2018_coords <- st_coordinates(bike_accidents_2018_sf)
bike_acc2019_coords <- st_coordinates(bike_accidents_2019_sf)
bike_acc2018_coords <- bike_acc2018_coords[,-3]
bike_acc2019_coords <- bike_acc2019_coords[,-3]

# First estimate a value for the bandwidth, using the "Plug-in" selector (Hpi).
h18 <- ks::Hpi(x = bike_acc2018_coords)
h19 <- ks::Hpi(x = bike_acc2019_coords)


# Now compute KDE; first without weights applied
fkde18 <- ks::kde(bike_acc2018_coords, H = h18)
fkde19 <- ks::kde(bike_acc2019_coords, H = h19)
```

::: {.panel-tabset .nav-pills}
# Unweighted KDE; plug-in bandwidth 2018 data
```{r}
# Plotting utilizes the specialized S3 plot.kde() function
plot(fkde18, display = "filled.contour2", 
     cont = c(10, 20, 30, 40, 50, 60, 70, 80, 90, 95, 100), asp = 1)
plot(bike_accidents_2018_sf, cex = 0.5, pch = 16, col = "black", add = TRUE)
```

# Unweighted KDE; plug-in bandwidth 2019 data
```{r}
plot(fkde19, display = "filled.contour2", 
     cont = c(10, 20, 30, 40, 50, 60, 70, 80, 90, 95, 100), asp = 1)
plot(bike_accidents_2019_sf, cex = 0.5, pch = 16, col = "black", add = TRUE)
```

# Unweighted KDE; smoothed cross validation bandwidth (SCV) 2018 data
```{r}
h18_scv <- ks::Hscv(x = bike_acc2018_coords)
fkde18_scv <- ks::kde(bike_acc2018_coords, H = h18_scv)
plot(fkde18_scv, display = "persp")
plot(bike_accidents_2018_sf, cex = 0.5, pch = 16, col = "black", add = TRUE)
```

# Unweighted KDE; smoothed cross validation bandwidth (SCV) 2019 data
```{r}
h19_scv <- ks::Hscv(x = bike_acc2019_coords)
fkde19_scv <- ks::kde(bike_acc2019_coords, H = h19_scv)
plot(fkde19_scv, display = "persp")
plot(bike_accidents_2019_sf, cex = 0.5, pch = 16, col = "black", add = TRUE)
```

# Unweighted KDE; least-squares cross validation bandwidth (LSCV) 2018 data
```{r}
h18_lscv <- ks::Hlscv(x = bike_acc2018_coords)
fkde18_lscv <- ks::kde(bike_acc2018_coords, H = h18_lscv)
plot(fkde18_lscv, display = "image", asp = 1)
plot(bike_accidents_2018_sf, cex = 0.5, pch = 16, col = "black", add = TRUE)
```

# Unweighted KDE; least-squares cross validation bandwidth (LSCV) 2019 data
```{r}
h19_lscv <- ks::Hlscv(x = bike_acc2019_coords)
fkde19_lscv <- ks::kde(bike_acc2019_coords, H = h19_lscv)
plot(fkde19_lscv, display = "image", asp = 1)
plot(bike_accidents_2019_sf, cex = 0.5, pch = 16, col = "black", add = TRUE)
```
:::

## Task 13
Compute the “volume of intersection” (“VI”) between the KDE surfaces (utilization distributions) of the two years. Hint: There are different ways to do that, but the adehabitatHR package has functionality for that. How do the results correspond to those of Task 9 (Jaccard Index or IoU)?



KOMMENTAR

## Task 14
Discuss your results for this part of DC1 (density estimation). What did you find? Compare the results of this part with the clusters/polygons of Parts 1 and 2 (see note below): What are the commonalities? What are the differences? Which method(s) perform more adequately than others for the given problem and data? Which method(s) would you recommend, and which ones not? Why? (You are free to add more points to the discussion.)

KOMMENTAR

# Fourth part: Second Order Properties
## Task 15
Choose one or more distance measure functions (justify your choice) and compute it/them for

KOMMENTAR

* a. all bicycle accidents (2011 - 2021) 

* b. bicycle accidents for one of the years selected in Task 6 

* c. bicycle accidents for only the cluster points of the year selected in (b)

Restrict your analysis to the “inner city” and use the same window for all point sets. It’s up to you to define the extent of the “inner city” and explain/justify what that means in terms of this data challenge.

KOMMENTAR

## Task 16
Now choose the following two pairs of years, 2018 & 2019, as well as 2018 & 2021, and compute the cross-X function, where “X” stands for the function(s) you used in Task 15. Use the AccidentYear as the marks to produce a marked point pattern.


## Task 17
Discuss your results. Similarities and differences between the various point sets? Noteworthy spatial and/or temporal patterns? Is any difference observable in the patterns of the cross-X function in the transition to the Covid-19 pandemic? etc. etc. Note: Consider in your interpretation that the distance scale may change between years.

KOMMENTAR 

## Task 18
From the bicycle accidents data, choose at least two relevant variables that make sense being compared, e.g. two different accident types, severity levels, times of day, years etc. For these selected accidents, compute the counts within the ‘statistical zones’ of Zurich and use these counts to compute the Getis-Ord G*-statistic for each of your counts layers. Visualize your results appropriately.


## Task 19
Discuss your results. What did you find regarding the hot and cold spots in your accident count layers? How do they compare to each other across layers and across (past) methods? etc. Discuss also the influence of the parameter settings (e.g., neighbor search distance, spatial weight formation) on your results.

KOMMENTAR


